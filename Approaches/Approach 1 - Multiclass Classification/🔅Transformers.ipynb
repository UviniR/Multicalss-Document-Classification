{"cells":[{"cell_type":"markdown","id":"92y3hqCTvnP8","metadata":{"id":"92y3hqCTvnP8"},"source":["# Model"]},{"cell_type":"code","execution_count":1,"id":"RpDtxERJmw0T","metadata":{"executionInfo":{"elapsed":7006,"status":"ok","timestamp":1696683837426,"user":{"displayName":"Uvini Ranaweera","userId":"03948925797394309986"},"user_tz":-330},"id":"RpDtxERJmw0T"},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","import tensorflow as tf\n","from tensorflow.keras.preprocessing.text import Tokenizer\n","from tensorflow.keras.preprocessing.sequence import pad_sequences\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Embedding, Conv1D, GlobalMaxPooling1D, Dense, Dropout\n","from sklearn.model_selection import train_test_split\n","import tensorflow as tf\n","import tensorflow_datasets as tfds\n","from keras.utils import to_categorical\n","from transformers import BertTokenizer, TFBertForSequenceClassification\n","from sklearn.metrics import classification_report"]},{"cell_type":"markdown","id":"9b2d7a74","metadata":{"id":"9b2d7a74"},"source":["<h3 style= \"color:blue;\"> Importing Data Set </h3>"]},{"cell_type":"code","execution_count":4,"id":"a7bc7d08","metadata":{"executionInfo":{"elapsed":1816,"status":"ok","timestamp":1696683854782,"user":{"displayName":"Uvini Ranaweera","userId":"03948925797394309986"},"user_tz":-330},"id":"a7bc7d08"},"outputs":[],"source":["# load your dataframe\n","df = pd.read_csv(\"Algorithms/Preprocessed.csv\",index_col=[0])"]},{"cell_type":"code","execution_count":5,"id":"9594916c","metadata":{"executionInfo":{"elapsed":4,"status":"ok","timestamp":1696683854782,"user":{"displayName":"Uvini Ranaweera","userId":"03948925797394309986"},"user_tz":-330},"id":"9594916c"},"outputs":[],"source":["# change both types into string\n","df['content'] = df['content'].astype('str')\n","df['fileclass'] = df['fileclass'].astype('str')"]},{"cell_type":"code","execution_count":6,"id":"0aa7c48c","metadata":{"executionInfo":{"elapsed":4,"status":"ok","timestamp":1696683854783,"user":{"displayName":"Uvini Ranaweera","userId":"03948925797394309986"},"user_tz":-330},"id":"0aa7c48c"},"outputs":[],"source":["# remove duplicates, leaving the first record\n","df = df.drop_duplicates(subset=['content'],keep=\"first\")"]},{"cell_type":"markdown","id":"4c6a1795","metadata":{"id":"4c6a1795"},"source":["<b> Before moving ahead let's convert the fileclass into integer format, as it will make our work easy!!</b>"]},{"cell_type":"code","execution_count":9,"id":"b1f74df1","metadata":{"executionInfo":{"elapsed":13,"status":"ok","timestamp":1696683886581,"user":{"displayName":"Uvini Ranaweera","userId":"03948925797394309986"},"user_tz":-330},"id":"b1f74df1"},"outputs":[],"source":["# Convert filecalss into int values\n","classes={'ChildProtection':0,'Cybersecurity':1,'DataPrivacy':2,'DataSystemsDevelopment':3,\n","         'DigitalFinance':4,'DigitalInclusion':5,'DigitalInformatioServices':6,\n","         'DigitalInfrastructure':7,'DigitalLiteracy':8,'DigitalServices':9,'Egovernment':10,'Upskilling':11\n","         }\n","# map the filecalss values\n","df['classes']=df['fileclass'].map(classes)\n","\n","# drop the fileclass axis\n","df.drop(['fileclass'], axis=1,inplace=True)"]},{"cell_type":"code","execution_count":10,"id":"H_coaXD_bxqN","metadata":{"executionInfo":{"elapsed":9,"status":"ok","timestamp":1696683886581,"user":{"displayName":"Uvini Ranaweera","userId":"03948925797394309986"},"user_tz":-330},"id":"H_coaXD_bxqN"},"outputs":[],"source":["# Assuming you have your data in a DataFrame named `df`\n","train_data = df['content'].tolist()\n","train_labels = df['classes'].tolist()\n","\n","# Split the data into training and testing sets\n","train_data, test_data, train_labels, test_labels = train_test_split(\n","    train_data, train_labels, test_size=0.3, random_state=42\n",")"]},{"cell_type":"code","execution_count":11,"id":"LL0rpeMxeuLQ","metadata":{"executionInfo":{"elapsed":194405,"status":"ok","timestamp":1696684080978,"user":{"displayName":"Uvini Ranaweera","userId":"03948925797394309986"},"user_tz":-330},"id":"LL0rpeMxeuLQ"},"outputs":[],"source":["# Load the BERT tokenizer\n","tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n","\n","# Tokenize and encode the training data\n","train_encodings = tokenizer(train_data, truncation=True, padding=True, max_length=300, return_tensors='tf')\n","\n","# Tokenize and encode the testing data\n","test_encodings = tokenizer(test_data, truncation=True, padding=True, max_length=300, return_tensors='tf')"]},{"cell_type":"code","execution_count":13,"id":"C5fPI_74fuzK","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":164691,"status":"ok","timestamp":1696684245660,"user":{"displayName":"Uvini Ranaweera","userId":"03948925797394309986"},"user_tz":-330},"id":"C5fPI_74fuzK","outputId":"a9655ab1-0439-42fc-a2f6-621365af0d79"},"outputs":[{"name":"stderr","output_type":"stream","text":["All PyTorch model weights were used when initializing TFBertForSequenceClassification.\n","\n","Some weights or buffers of the TF 2.0 model TFBertForSequenceClassification were not initialized from the PyTorch model and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]}],"source":["# Assuming you have your data in a DataFrame named `df`\n","train_data = df['content'].tolist()\n","train_labels = df['classes'].tolist()\n","\n","# Split the data into training and testing sets\n","train_data, test_data, train_labels, test_labels = train_test_split(\n","    train_data, train_labels, test_size=0.2, random_state=42\n",")\n","\n","# Load the BERT tokenizer\n","tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n","\n","# Tokenize and encode the training data\n","train_encodings = tokenizer(train_data, truncation=True, padding=True, max_length=100, return_tensors='tf')\n","\n","# Tokenize and encode the testing data\n","test_encodings = tokenizer(test_data, truncation=True, padding=True, max_length=100, return_tensors='tf')\n","\n","# Convert the labels to TensorFlow tensors\n","train_labels = tf.convert_to_tensor(train_labels)\n","test_labels = tf.convert_to_tensor(test_labels)\n","\n","# Load the pre-trained BERT model\n","model = TFBertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=12)\n","\n","# Compile the model\n","model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=2e-5),\n","              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n","              metrics=['accuracy'])\n","\n","\n"]},{"cell_type":"code","execution_count":14,"id":"fmBAz-uBP6Bn","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":423,"status":"ok","timestamp":1696684283012,"user":{"displayName":"Uvini Ranaweera","userId":"03948925797394309986"},"user_tz":-330},"id":"fmBAz-uBP6Bn","outputId":"e730a46e-c863-477a-ef66-4d448dc06489"},"outputs":[{"name":"stdout","output_type":"stream","text":["Model: \"tf_bert_for_sequence_classification\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," bert (TFBertMainLayer)      multiple                  109482240 \n","                                                                 \n"," dropout_37 (Dropout)        multiple                  0         \n","                                                                 \n"," classifier (Dense)          multiple                  9228      \n","                                                                 \n","=================================================================\n","Total params: 109491468 (417.68 MB)\n","Trainable params: 109491468 (417.68 MB)\n","Non-trainable params: 0 (0.00 Byte)\n","_________________________________________________________________\n"]}],"source":["model.summary()"]},{"cell_type":"code","execution_count":null,"id":"e2Q1I_qvPOKB","metadata":{"id":"e2Q1I_qvPOKB"},"outputs":[],"source":["# Fine-tune the model on your training data\n","model.fit(train_encodings['input_ids'], train_labels, epochs=10, batch_size=64)\n","\n","# Make predictions on the test data\n","predicted_labels = model.predict(test_encodings['input_ids']).logits.argmax(axis=1)\n","\n","# Generate classification report\n","report = classification_report(test_labels, predicted_labels)\n","\n","print(report)"]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.12"}},"nbformat":4,"nbformat_minor":5}
