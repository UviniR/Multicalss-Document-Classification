Global efforts are underway to improve education 
quality—to ensure children are not only in school but 
learning and developing to their full potential. Although 
many theories exist on the best approaches to improve 
education quality, policymakers and implementers 
need evidence on which programs are effective at 
helping children actually learn while in school. 
Innovations for Poverty Action (IPA) is a research 
and policy nonprofit that discovers and advances 
what works to reduce poverty and improve lives. 
In addition to conducting rigorous research, IPA 
reviews and consolidates research for policy makers and practitioners. The objective is to distill 
complex, nuanced, and dynamic research findings 
into focused and actionable recommendations.  
 
This brief summarizes and provides key lessons from 
multiple meta-analyses and over two-dozen randomized 
evaluations (both IPA and non-IPA studies) on improving 
learning outcomes in low-income countries, with a 
focus on basic education. To identify relevant studies, 
we searched institutional websites (including IPA’s 
and J-PAL’s), Google Scholar, and the literature review 
sections of key papers. In addition, we consulted with 
leading experts in the field to identify any gaps.
Teacher professional development 
programs that provide teachers with 
concrete tools to improve the quality of 
instruction, and offer continued support, 
improved student outcomes. 
Performance-based incentives can 
improve student learning, particularly 
when combined with other inputs—but 
the design of the incentive matters.
Inquiry and problem-based 
pedagogy—in which students learn 
by collaboratively solving real-life authentic problems—improved 
children’s math and science abilities.  
  
Distributing information 
communications technology (ICT) alone 
has not improved learning; but ICT 
can be an effective tool for delivering 
quality instruction when integrated 
into existing curricula and teaching 
processes. 
 
Targeting instruction to students’ 
achievement levels improved learning 
for low-performing pupils. Lessons on improving learning outcomes (supporting studies below)
Important note:  While all the interventions in this brief have been rigorously tested in different countries and/or contexts, sometimes solutions that 
work in one or more situations may not work as well in another. Quality implementation and monitoring are key, and further evaluation is often needed 
as programs are adapted to a new context or at a new scale. In addition, these lessons will evolve and change as new evidence emerges. 
PHOTO: STELLA BENEZRAEVIDENCE REVIEW
Improving Learning Outcomes
Lessons from rigorous evidence
Teacher professional development 
programs that provide teachers with 
concrete tools to improve the quality 
of instruction and offer continued 
support improved student outcomes.  
 
A meta-analysis of rigorous evaluations of education 
interventions in sub-Saharan Africa suggests that providing 
teachers with repeated teacher training with long-term 
mentoring or coaching can be effective at improving 
student performance.1 The meta-analysis also suggests that 
pedagogical interventions involving teacher training can 
potentially affect cohort after cohort of students, producing 
a multiplier effect on student learning in the long-run.  
 
Randomized evaluations from programs in Kenya and 
Uganda suggest teacher professional development 
programs that provide teachers with concrete tools (e.g., 
scripted lesson plans and/or step-by-step processes) to 
improve the quality of their instruction in a lasting manner 
can improve literacy. In Kenya and Uganda, for example, 
researchers evaluated the impact of the Reading to Learn 
program on early-grade literacy rates. The program trained 
lower primary school teachers on a highly structured 
five-step process for developing children’s literacy skills, 
accompanied by resources and mentoring. This initiative 
started when students were in grades 1 and 2 and lasted for 
1.5 to 2 years. During the follow-up, students' scores were 
higher on assessments of oral literacy in both countries and 
written literacy in Uganda.2  
 
Another randomized evaluation of a literacy program in 
Kenya provided teachers with 140 sequential, semi-scripted 
lesson plans for literacy sessions in both Swahili and 
English. The program also conducted teacher training, 
including a three-day initial workshop, a problem-solving 
workshop four months into the school year, and a refresher 
training the following school year. Children who received 
the literacy intervention scored significantly higher in 
English spelling, Swahili letter reading, and the reading 
of words and passages in both English and Swahili. The 
program also reduced school dropout rates from five 
percent to two percent, suggesting that the problem of 
school dropout in Kenya could be tackled by improving 
education quality. Researchers reduced the cost of the 
program by sending weekly text messages to teachers 
that provided brief instructional tips and motivation to 
implement lesson plans.3 Another study in Kenya evaluated the impacts of an 
initiative that provided teachers with structured teacher 
lesson plans in combination with instructional support, 
coaching, and student books. The results demonstrated 
that adding structured teacher lesson plans was most 
effective in improving learning outcomes across grades 
and subjects.4 The proven elements of the initiative are 
being scaled up across Kenya through the Tusome literacy 
program. A comparison of outcomes from 2015 to 2016 
suggested the program improved English and Swahili 
learning outcomes.5
Performance-based incentives can 
improve student learning, particularly 
when combined with other inputs—
but the design of the incentive 
matters. 
 
A review of rigorous evaluations of education interventions 
in low- and middle-income countries suggests that teacher 
performance incentives, which reward teachers based 
on the performance improvements of their students, can 
improve learning outcomes. It also raises questions about 
how to best design such incentives to maximize learning, 
while minimizing strategic responses.6 
 
Evaluations from Kenya, Tanzania, Uganda, India, and 
Pakistan also found performance-based teacher bonuses 
improved student performance, but that only some designs 
led to actual improved learning.  
PHOTO: FRANCISCA DE IRUARRIZAGA
For example, in Kenya, researchers found that a program 
that gave teachers prizes based on student performance 
increased exam scores over a two-year period. However, 
the program did not improve students’ scores on tests of 
the same subjects that were not linked to the incentives. 
Much of the increase in test scores was due to increased 
teacher test preparation sessions and improved test-taking 
skills such as strategies for answering multiple-choice 
questions or memorization, as opposed to increased overall 
knowledge.7 
 
In Tanzania, researchers found some evidence that 
providing teachers with performance-based bonuses, linked 
to the number of their students who passed basic tests of 
math, Swahili, and English based on the national curriculum, 
improved learning outcomes. When provided with 
unconditional grants to schools, the incentives had larger, 
positive effects on learning (though grants alone had no 
impact). The results suggest that providing inputs to schools 
together with performance-based incentives has a greater 
impact than the sum of the individual effects.8  
 
In Uganda, researchers used a different model of 
performance-based bonuses—pay for percentile (PFP). 
Under this scheme, teachers earned a bonus payment 
based on how well their students performed relative to 
other students with similar baseline test scores, effectively 
the student’s percentile in their peer group. Teachers 
responded to the incentives by putting forth more effort, 
spending more hours per week preparing lessons and 
grading assignments. Further, the incentives increased 
student attendance. Achievement gains only occurred 
in schools that provided grade 6 math students with textbooks and among those students whose learning 
levels were appropriate for those textbooks, pointing to 
the complementarity of incentives, appropriately-leveled 
teaching, and learning materials in increasing student 
achievement.9  
 
In India, researchers found that linking student test 
performance to teacher pay significantly improved learning 
outcomes for students in government schools in Andhra 
Pradesh. Student learning improved significantly on 
math and language tests that were designed based on 
the syllabus. Incentive schools did significantly better on 
both mechanical and conceptual components of the test, 
suggesting that the gains in test scores represent an actual 
increase in learning outcomes.10 
Incentive schools did significantly better on 
both mechanical and conceptual components 
of the test, suggesting that the gains in test 
scores represent an actual increase in learning 
outcomes.
In Pakistan, researchers evaluated a program offering yearly 
cash bonuses to teachers linked to gains in student exam 
scores, school enrollment, and the level of student exam 
participation. The program increased school enrollment 
and student exam participation rates but did not increase 
student exam scores. The findings suggest that when faced 
with incentives for multiple outcomes, teachers may try to 
influence the outcomes that they can improve most easily.11
PHOTO: AUDE GUERRUCCIInquiry and problem-based 
pedagogy—in which students learn 
by collaboratively solving real-life 
authentic problems—improved 
children’s math and science abilities.  
 
Ten randomized evaluations from four countries in the 
Americas—Argentina, Belize, Paraguay, and Peru—found 
that using inquiry and problem-based pedagogy (IPP) 
increased pupils’ math and science scores on standardized 
tests.12 The evaluations were conducted across a wide 
range of geographic, socio-economic, teacher background, 
and age and grade contexts (preschool, 3rd grade and, 4th 
grade).13 
 
While the interventions varied by grade level, national 
curriculum, and subject area (mathematics or science), 
all shared three central elements of IPP: (1) instruction 
organized around core concepts that were developed over 
many lessons, (2) classes organized around inquiry and 
problem-solving opportunities, and (3) use of structure and 
scaffolding to help students do more complex activities and 
make sure that they have close guidance.  
 
Across the ten studies, researchers found that IPP led to a 
0.18 standard deviation increase in math test scores overall 
and a 0.16 standard deviation increase in science test scores 
overall. Each program trained teachers (or in Peru, tutors) in IPP 
methods and lesson plans, provided didactic materials to 
enhance learning through hands-on activities, and provided 
ongoing supervision. All programs included a detailed 
lesson by lesson curriculum and a minimum of 20 hours 
of teacher professional development. The sessions aimed 
to have teachers learn through practice and interactions 
with other teachers. In addition, all programs provided 
continuous in-school teacher support.  
 
According to researchers’ estimates, the cost of a 0.10 
standard deviation increase in math test scores overall is 
$14.53 per student. This estimate varies from $6.90 per 
student in Argentina 2009 to $22.48 in Paraguay 2013. The 
cost of a 0.10 standard deviation increase in science test 
scores overall is $14.64 per student and varies from $8.40 
per student in Belize 2015 to $17.52 in Peru 2010 (where 
tutors, who were more expensive, were used).
From this ten country study, researchers 
concluded that implementing IPP learning in 
Latin America, if not worldwide, would greatly 
enhance students’ learning in math and 
science. 
Researchers concluded that implementing IPP learning 
in Latin America, if not worldwide, would greatly enhance 
students’ learning in math and science.
Distributing information 
communications technology (ICT) 
alone has not improved learning; 
but ICT can be an effective tool for 
delivering quality instruction when 
integrated into existing curricula and 
teaching processes.  
 
A meta-analysis of randomized evaluations of education 
interventions in developing country primary schools 
suggests that ICT programs are most effective when 
they are a complement to, rather than a substitute for 
classroom instruction.14 The meta-analysis indicates that 
ICT interventions have smaller effects when they are 
unaccompanied by parent or student training, or when ICT 
use appears to substitute away from useful instructional 
time during school hours.  
 
Evidence from India, Ghana, Kenya, and Pakistan found 
certain ICT interventions made it easier to deliver high-
quality instruction and/or the official curriculum, leading 
to positive improvements in student learning that are 
tailored to student levels. For example, rigorous research 
in India found that Computer Assisted Learning (CAL) 
programs that integrate a targeted educational software to 
the regular school curriculum led to some higher learning 
outcomes. The math test scores of those who participated 
in the program significantly increased after two years in the 
program.15 
PHOTO: ARVIND EYUNNI
In India, researchers also studied the impact of the 
“Mindspark” program, a CAL software that provides 
students with personalized instruction, on the learning 
outcomes of middle school students. Mindspark uses a set 
of games, videos, and activities that pull from a database 
of over 45,000 questions to test students and provide 
explanations and feedback. A key feature of the Mindspark 
program is its ability to use data to identify the learning level 
of every student, deliver customized content targeted at 
this level, and dynamically adjust to the student’s progress. 
Also, as an after school program, it doesn’t take away from 
class time. Researchers found that the Mindspark program 
improved performance in both math and Hindi across 
multiple grade levels.16 
 
Researchers conducted a randomized evaluation assessing 
whether reliable, high-quality interactive distance-learning 
classes improved learning outcomes among marginalized 
school children in rural Ghana. The program, called Making 
Ghanaian Girls Great (MGCubed), used solar panels, a 
satellite modem, projector, webcam, microphones, and 
other technologies to transmit mathematics and English 
instruction by well-trained instructors in real-time. The 
program also trained school-based facilitators to manage 
classrooms and contribute to the instruction in case the 
technology failed. After two years, the program significantly 
improved students’ numeracy skills, foundational and 
pre-reading skills, and word-naming fluency.17  
 
In Kenya, researchers conducted a randomized evaluation 
testing the impacts of providing tablets to instructional 
supervisors and teachers and providing e-readers to 
students on learning outcomes. Teachers were trained 
for ten days on how to use the tablets, and the content 
and tools were designed to supplement the Kenyan 
curriculum.18 All three interventions, which were part of the 
PRIMR initiative, led to significant improvements in English 
and Swahili literacy assessments, specifically in oral reading 
fluency.19 The use of tablets for instructional supervisors 
and teachers is being scaled up across Kenya through the 
Tusome literacy program.20  
 
The eLearn program implemented through the government 
of Punjab, Pakistan created short videos that corresponded to the official curriculum in 8th-grade math and science. 
Teachers in treatment schools received tablets with these 
videos pre-loaded and training on how to use them to 
augment, not replace, their existing teaching practices. In 
each classroom, LED screens were installed in the front 
of the classroom to display these videos. After only four 
months, the program significantly increased student math 
and science achievement.21  
 
Yet not all ICT programs have been effective. For example, 
in Peru, 40,000 laptops were distributed to about 500 
schools in the country’s poorest regions as part of the One 
Laptop per Child (OLPC) program. After 15 months, those 
who received the program showed no improvement in 
math or language test scores, but some positive effects 
were found in their cognitive skills. There was also no effect 
on the motivation of students to attend school and do 
homework as compared to students in other schools.22 
 
Similarly, in Colombia, the Computadores para Educar 
program aimed to not only increase computer units 
in schools but also train teachers on how to use the 
technology in teaching specific subjects, particularly 
Spanish. Teachers underwent a 20-month training program. 
However, the program did not improve students’ math and 
Spanish test scores. There was no effect on other academic 
outcomes, such as on the hours of study, students’ 
perception of school, and their relationships with peers.23   
PHOTO:  LOÏC WATINE
MGCubed Program Improved Math, Reading, Foundational LiteracyThe findings suggest that while ICT has the potential to 
improve instructional quality, it is not a solution in and of 
itself and runs the risk of being a waste of resources if it 
fails to be incorporated into existing educational processes 
and curricula or is not accompanied by sufficient teacher 
training and support.
While ICT has the potential to improve 
instructional quality, it is not a solution in and 
of itself and runs the risk of being a waste of 
resources if it fails to be incorporated into 
existing educational processes and curricula 
or is not accompanied by sufficient teacher 
training and support.Targeting instruction to students’ 
achievement levels has been 
shown to improve learning for low-
performing pupils.  
According to a narrative review of randomized evaluations 
of interventions designed to increase attendance and/or 
learning, pedagogical interventions that match teaching 
to students’ learning levels are effective at improving 
learning.24 Targeting instruction to a student’s initial level 
of preparedness increases test scores and both higher and 
lower levels of initial preparedness.  
 
Evidence from Kenya, Ghana, and India also supports 
tailoring instruction to students’ level, rather than to the 
curriculum, as a way to improve learning outcomes.  
 
PHOTO: JESSICA KIESSEL
In India, for example, results from multiple evaluations, 
beginning as early as 2001, show that programs that teach 
at the level of the child are consistently effective in raising 
student test scores.  In one of these landmark studies, 
researchers worked with the education NGO, Pratham, 
to evaluate the Balsakhi Program, a remedial education 
intervention in which a tutor met with small groups of 
children every day who were falling behind their peers to 
work on basic numeracy and literacy skills. The program 
had substantial positive impacts on children’s academic 
achievement.25  
 
In India, researchers evaluated efforts to scale up Pratham’s 
approach to teaching children according to their learning 
level in the government school system in four Indian 
states. In the first two instances (Bihar and Uttarakhand), 
the targeted instruction methodology was not adopted by 
government schoolteachers, despite training sessions and 
Pratham support. Researchers adapted the evaluation in 
Haryana and Uttar Pradesh to include improved monitoring 
support and “learning camps” that took place during school 
hours, with additional 10-day summer camps. Both models 
proved effective, with increases in language test scores for 
students enrolled in these schools. These two models provide blueprints that can be replicated 
in other government systems and contexts.26 
 
In Kenya, tracking students by prior achievement raised 
scores for all students, even those assigned to lower-
achieving peers. On average, after 18 months, test scores 
were 0.14 standard deviations higher in tracking schools 
than in non-tracking schools.27 
 
In Ghana, a nationwide evaluation across 500 schools 
found significant improvements in numeracy and 
literacy on average, with regional variations highlighting 
the importance of implementation quality. The Ghana 
evaluation tested four different variations of the program: 
in-school remedial lessons with an assistant, after-school 
remedial lessons with an assistant, in-school curriculum 
level lessons with an assistant, and teacher-led targeted 
instruction during school. When considering results from 
oral tests, all program variations performed approximately 
equally well and better than the comparison group. The 
in-school and after-school remedial lessons delivered by 
teacher community assistants had the most consistent 
positive impact on pupil achievement, including on tests 
that involved harder, written content.28
PHOTO: FRANCISCA DE IRUARRIZAGAProject Development: pd@poverty-action.org | General Inquiries: contact@poverty-action.org | www.poverty-action.org
Innovations for Poverty Action (IPA) is a research and policy nonprofit that discovers and promotes effective 
solutions to global poverty problems. IPA designs, rigorously evaluates, and refines these solutions and their 
applications together with researchers and local decision-makers, ensuring that evidence is used to improve 
the lives of the world’s poor. Our well-established partnerships in the countries where we work, and a strong 
understanding of local contexts, enable us to conduct high-quality research. This research has informed hundreds 
of successful programs that now impact millions of individuals worldwide.References
1. Conn, Katharine M. 2017. “Identifying Effective Education Interventions 
in Sub-Saharan Africa: A Meta-Analysis of Impact Evaluations.” 
Review of Educational Research. 87 (5): 863-898. https://doi.
org/10.3102/0034654317712025
2. Lucas, Adrienne M., Patrick J. McEwan, Moses Ngware, and Moses Oketch. 
2014. “Improving Early-Grade Literacy in East Africa: Experimental Evidence 
from Kenya and Uganda.” Journal of Policy Analysis and Management 33 (4): 
950–76. https://doi.org/10.1002/pam.21782. 
3. Jukes, Matthew C. H., Elizabeth L. Turner, Margaret M. Dubeck, Katherine 
E. Halliday, Hellen N. Inyega, Sharon Wolf, Stephanie Simmons Zuilkowski, 
and Simon J. Brooker. 2016. “Improving Literacy Instruction in Kenya 
Through Teacher Professional Development and Text Messages Support: 
A Cluster Randomized Trial.” Journal of Research on Educational Effectiveness 
10 (3): 449–81. https://doi.org/10.1080/19345747.2016.1221487. 
4. Piper, Benjamin, Stephanie Simmons Zuilkowski, Margaret Dubeck, 
Evelyn Jepkemei, and Simon J. King. 2018. “Identifying the Essential 
Ingredients to Literacy and Numeracy Improvement: Teacher Professional 
Development and Coaching, Student Textbooks, and Structured Teachers’ 
Guides.” World Development 106 (June): 324–36. https://doi.org/10.1016/j.
worlddev.2018.01.018. 
5. Piper, Benjamin, Joseph Destefano, Esther M. Kinyanjui, and Salome 
Ong’ele. 2018. “Scaling up Successfully: Lessons from Kenya’s Tusome 
National Literacy Program.” Journal of Educational Change 19 (3): 293–321. 
https://doi.org/10.1007/s10833-018-9325-4.
6. Ganimian, Alejandro J. and Richard J. Murnane. 2014. “Improving 
Educational Outcomes in Developing Countries: Lessons from Rigorous 
Impact Evaluations.” National Bureau of Economic Research Working Paper 
No. 20284. https://www.nber.org/papers/w20284.pdf
7. Glewwe, Paul, Nauman Ilias, and Michael Kremer. 2010. “Teacher 
Incentives.” American Economic Journal: Applied Economics 2 (3): 205–27. 
https://doi.org/10.1257/app.2.3.205. 
8. Mbiti, Isaac, Karthik Muralidharan, Mauricio Romero, Youdi Schipper, 
Constantine Manda, and Rakesh Rajani. 2018. “Inputs, Incentives, and 
Complementarities in Education: Experimental Evidence from Tanzania.” 
Working Paper 24876. National Bureau of Economic Research. https://doi.
org/10.3386/w24876. 
9. Gilligan, Daniel O., Naureen Karachiwalla, Ibrahim Kasirye, Adrienne Lucas, 
and Derek Neal. 2018. “Educator Incentives and Educational Triage in Rural 
Primary Schools.” IZA Institute of Labor Economics DP No. 11516. http://ftp.
iza.org/dp11516.pdf
10. Muralidharan, Karthik, and Venkatesh Sundararaman. 2011. “Teacher 
Performance Pay: Experimental Evidence from India.” Journal of Political 
Economy 119 (1): 39–77. https://doi.org/10.1086/659655. 
11. Barrera-Osorio, Felipe, and Dhushyanth Raju. 2017. “Teacher Performance 
Pay: Experimental Evidence from Pakistan.” Journal of Public Economics 148 
(April): 75–91. https://doi.org/10.1016/j.jpubeco.2017.02.001. 
12. Bando, Rosangela, Emma Näslund-Hadley, and Paul Gertler. "Inquiry and 
Problem Based Pedagogy: Evidence from 10 Field Experiments." (2018). 
https://publications.iadb.org/en/inquiry-and-problem-based-pedagogy-
evidence-10-field-experiments
13. The IPP evaluations were funded by the Inter-American Development Bank 
(IDB). 
14. McEwan, Patrick J. 2015. “Improving Learning in Primary Schools of 
Developing Countries: A Meta-Analysis of Randomized Experiments.” 
Review of Educational Research, 85(3): 353-394. https://doi.
org/10.3102/0034654314553127
15. Banerjee, A. V., S. Cole, E. Duflo, and L. Linden. 2007. “Remedying 
Education: Evidence from Two Randomized Experiments in India.” The 
Quarterly Journal of Economics 122 (3): 1235–64. https://doi.org/10.1162/
qjec.122.3.1235.  16. Muralidharan, Karthik, Abhijeet Singh, and Alejandro J. Ganiman. 2019. 
“Disrupting Education? Experimental Evidence on Technology-Aided 
Instruction in India.” American Economic Review, 109(4):1426-60. https://
www.aeaweb.org/articles?id=10.1257/aer.20171112
17. Johnston, Jamie, and Christopher Ksoll. 2017. “Effectiveness of Interactive 
Satellite-Transmitted Instruction: Experimental Evidence from Ghanaian 
Primary Schools.” Center for Education Policy Analysis Working Paper No. 
17-08. https://www.poverty-action.org/sites/default/files/publications/
Effectiveness-Interactive-Satellite-Transmitted-Instruction.pdf
18. The teachers' tablets contained multimedia lesson plans, supplementary 
pedagogical aids, virtual letter flashcards, and the Papaya™ software 
application, which had audio capabilities to practice letter sounds. The 
tablet also included the Tangerine: Class™ application, which contained a 
sophisticated continuous assessment program that allowed teachers to 
systematically investigate the quality of pupil learning and compare it with 
their instruction to determine which lessons they should reemphasize, 
based on pupil mastery of the content. The pupil e-readers contained the 
PRIMR reading textbooks in English and Kiswahili, as well as books in the 
primary mother tongue in the area (i.e., Dholuo), relevant textbooks from 
Kenyan publishers, and hundreds of age appropriate stories related to the 
Kenyan curriculum, as well as English and Kiswahili dictionaries
19. Piper, Benjamin, Evelyn Jepkemei, Dunston Kwayumba, Kennedy Kibukho. 
2015. “Kenya’s ICT Policy in Practice: The Effectiveness of Tablets and 
E-readers in Improving Student Outcomes.” FIRE: Forum for International 
Research in Education, 2 (1). https://preserve.lehigh.edu/cgi/viewcontent.
cgi?referer=&httpsredir=1&article=1025&context=fire
20. Piper, Benjamin, Joseph Destefano, Esther M. Kinyanjui, and Salome 
Ong’ele. 2018. “Scaling up Successfully: Lessons from Kenya’s Tusome 
National Literacy Program.” Journal of Educational Change 19 (3): 293–321. 
https://doi.org/10.1007/s10833-018-9325-4.
21. Beg, Sabrin, Adrienne M. Lucas, Waqas Halim, Umer Saif. 2018. “Tools 
for Teaching: Leveraging Technology to Improve Classroom Content 
Delivery.” Working paper. https://events.barcelonagse.eu/live/files/2265-
sabrinbeg61091pdf 
22. Cristia, Julian, Pablo Ibarrarán, Santiago Cueto, Ana Santiago, and Eugenio 
Severín. 2012. “Technology and Child Development: Evidence from the One 
Laptop per Child Program.” IDB Working Paper No. 304. https://papers.ssrn.
com/sol3/papers.cfm?abstract_id=2032444
23. Barrera-Osorio, Felipe, and Leigh L. Linden. 2009. “The Use and Misuse 
of Computers in Education: Evidence from a Randomized Experiment in 
Colombia.” World Bank Policy Research Working Paper 4836. https://dash.
harvard.edu/ handle/1/8140109. 
24. Kremer, Michael, Conner Brannen, Rachel Glennerster. 2013. “The 
Challenge of Education and Learning in the Developing World.” Science 
340:297-300. https://science.sciencemag.org/content/340/6130/297.full
25. Banerjee, A. V., S. Cole, E. Duflo, and L. Linden. 2007. “Remedying 
Education: Evidence from Two Randomized Experiments in India.” The 
Quarterly Journal of Economics 122 (3): 1235–64. https://doi.org/10.1162/
qjec.122.3.1235.
26. Banerjee, Abhijit, Rukmini Banerji, James Berry, Esther Duflo, Harini 
Kannan, Shobhini Mukherji, Marc Shotland, and Michael Walton. 2016. 
“Mainstreaming an Effective Intervention: Evidence from Randomized 
Evaluations of ‘Teaching at the Right Level’ in India.” National Bureau of 
Economic Research Working Paper 22746. https://www.nber.org/papers/
w22746.pdf
27. Duflo, Esther, Pascaline Dupas, and Michael Kremer. "Peer effects, teacher 
incentives, and the impact of tracking: Evidence from a randomized 
evaluation in Kenya." American Economic Review 101, no. 5 (2011): 1739-74. 
https://www.poverty-action.org/publication/peer-effects-and-impact-
tracking-evidence-randomized-evaluation-kenya
28. “Evaluating the Teacher Community Assistant Initiative in Ghana.” 2015. 
Innovations for Poverty Action. https://www.poverty-action.org/study/
evaluating-teacher-community-assistant-initiative-ghana.
Writers: Laura Burke, Shahana Hirji  |  Editor: Laura Burke  |  Designer: Michelle Read DECEMBER 2019Acknowledgments: We would like to thank Annie Duflo, Sarah Kabay, Adrienne Lucas, Heidi McAnnally-Linz, Emma Naslund-Hadley, and 
Sharon Wolf for providing thoughtful input into this brief, as well as Matthew Jukes for providing valuable input on an earlier version. 