New powers,  
new responsibilities
A global survey of journalism 
and artificial intelligence
Charlie BeckettPreface
No, the robots are not going to take over journalism. Yes, the machines might 
soon be able to do much routine journalism labour. But the reality and the 
potential of artificial intelligence (AI), machine learning, and data processing is to 
give journalists new powers of discovery, creation and connection.1
The hope is that journalists will be algorithmically turbo-charged, capable of 
using their human skills in new and more effective ways. AI could also transform 
newsrooms from linear production lines into networked information and 
engagement hubs that give journalists the structures to take the news industry 
forward into the data-driven age. 
Algorithms will power the systems. But the human touch – the insight and 
judgement of the journalist – will be at a premium. Can the news industry seize 
this opportunity? 
The Internet, social media, and mobile communications have already provided 
new tools and pathways for journalism to meet the profound challenges of the 
digital age. Now AI technologies promise another leap forward. 
But what of the economic, ethical, and editorial threats they also bring? The 
algorithmically-augmented journalist and the artificially intelligent news 
organisation of the 21st century are entering another major transitional phase. 
How will journalism sustain its public value? 
This report is a first step towards understanding what the news media thinks 
about AI and what it might do next. Step away from the hype and paranoia for an 
hour and read what journalists reckon AI means for them.
Professor Charlie Beckett  
LSE, November 2019
Preface
2 11  
Contents
Preface   1
Contents  2
The Journalism AI Survey 4
Executive Summary  6
Introduction: The Journalism AI Report  12
   Newsroom Definitions of Artificial Intelligence  15
Chapter 1: How AI is Being Used in Journalism Today  20
 1.0 What Newsrooms are Doing and Why  20
 1.1 Newsgathering  22
 1.2 News Production  23
 1.3 News Distribution  28
 1.4 Why Newsrooms Use AI  32
 1.5 What is Working and What is Not  34
Chapter 2: AI Strategy  37
 2.0 The Need for Strategy  37
 2.1 News Organisations’ AI Strategies  39
 2.2 Ready for AI?  41
 2.3 How Newsroom Roles are Affected by AI  43
 2.4 The Strategic Challenges to AI Adoption  47
 2.5 The Pathway to an AI Strategy  51
Contents
2Chapter 3: Ethics and Editorial Policy 52
 3.0 What Difference Does AI Make? 52
 3.1 Economics: Savings or Investment? 55
 3.2 Algorithmic Bias 56
 3.3 Misinformation and ‘Filter Bubbles’ 57
 3.4 Can AI Enhance Editorial Decisions and Transparency? 59
 3.5 Balancing Artificial and Human Intelligence 63
 3.6 The Role of the Technology Companies 64
 3.7 How Should Journalists Debate AI Ethics? 68
Chapter 4: The Future of AI and Journalism 69
 4.0 Where is This All Going? 69
 4.1 Future Applications and Strategy 70
 4.2 The Need for Education and Training 73
 4.3 Newsroom Collaboration 76
 4.4  Collaboration with Universities 79
 4.5 How Will AI Reshape Journalism? 81
 4.6 Augmentation or Transformation? 82
 4.7 What Can Newsrooms Learn from Other Industries? 86
Conclusion: What Does AI Mean for Journalism? 89
Glossary 92
Endnotes 98
Readings and Resources 107
Acknowledgments 108
4 3 Character illustrations created by rawpixel.com    
The Journalism AI Survey
This report is based on a survey of the state of mind and state of 
play in 71 news organisations from 32 different countries regarding 
artificial intelligence (AI) and associated technologies. We asked a wide 
range of journalists working with AI to answer questions about their 
understanding of AI, how it was used in their newsrooms, their views on 
the wider potential and risks for the news industry, and about ethical and 
editorial implications. It was supplemented with interviews, workshops, 
and conversations at journalism conferences.
NEWS ORGANISATIONS THAT COMPLETED THE SURVEY, BY TYPE
20
15
10
5
0
Newspapers Broadcasters Publishing 
GroupsNews 
AgenciesMagazines Others21
9
16
14
65
Most of the respondents were technologically expert 
and could be called ‘digital early adopters’, so they 
have more awareness of AI than a random sample 
of journalists. We encouraged news organisations to 
gather representatives from different departments to 
complete the survey collaboratively. 116 journalists 
contributed to the survey, bringing their perspective on 
AI from a number of different departments.
The Journalism AI Survey
4SURVEY RESPONDENTS, BY DEPARTMENTS WHERE THEY WORK
23%
21%
15%13%8%7%7%6%  Leadership – 23%
  Innovation – 21%
  Data – 15%
  Product – 13%
  Editorial – 8%
   Strategy and Partnerships – 7%
   Audience and Marketing – 7%
  AI-specific roles  – 6%
Inevitably, the sample is skewed towards better resourced and more 
technologically developed markets such as the USA and Europe. We do 
not claim that the survey is representative of the global industry – that 
would be almost impossible on an international scale – nor does it reflect 
equally all viewpoints within the different parts of news organisations. But 
it does give an unprecedented insight into how these technologies are 
perceived by those people leading their development or application inside 
news organisations.
COUNTRIES REPRESENTED IN THE JOURNALISM AI SURVEY
 
NB: The list of organisations that completed the survey can be found in the acknowledgments.
The published quotes have generally been anonymised. Some quotes were 
edited lightly to correct literals and for sense. The editorial responsibility for 
the report lies entirely with the author.
6 51 Artificial intelligence (AI) as a range of technologies including 
machine learning, automation and data processing is a significant 
part of journalism already but it is unevenly distributed.
2 Its future impact is uncertain but AI has the potential for wide-ranging 
and profound influence on how journalism is made and consumed.
3 Even the newsrooms we surveyed that are furthest ahead in the 
adoption of AI described it as additional, supplementary and 
catalytic, not yet transformational. 
4 The power and potential described in this report make it clear that all 
newsrooms should pay attention to AI.
5	 AI	is	defined	by	newsrooms	as	human	or	technologically	related	and	
by its function.
6 It is important to have an organisational definition of AI to help 
shape strategy and to promote understanding and communication 
about AI in the newsroom.
7 Just under half of respondents said they use AI for newsgathering, 
two-thirds said they used it for production and just over half said 
they employed AI for distribution.
8 There was a general aspiration to use any 
efficiencies	to	free	up	resources	for	enhanced	
newsroom functionality and for new or 
improved content and services.Executive Summary
Executive Summary
69 The three key motives for using AI were:
 • To make journalists’ work more efficient (68 per cent of replies)
 • To deliver more relevant content to users (45 per cent)
 • To improve business efficiency (18 per cent).
10 Just over a third of our respondents claimed to have an active  
AI strategy.
11 There were four main approaches to creating an AI strategy:
 • Traditional management in existing departments
 • Separate teams working on AI projects
 • Integrated tech and editorial structures
 • Experimental teams - separate or integrated.
12 The newsrooms split approximately in half between those who felt 
they were AI-ready and those who were just starting or still planning 
to use AI.
13 There was a significant fear of their newsroom falling behind. 
This was a particular problem for small newsrooms, raising 
the prospect of growing inequality between small and large 
organisations.
14 Newsroom roles were seen to be changing more through the 
augmentation of current roles rather than the replacement of jobs. 
There would be new tasks for people in existing roles and new 
workflows,	but	few	AI-specific	new	roles.
15 The biggest challenges to adopting AI cited by our respondents were 
financial	resources	(27	per	cent)	and	knowledge	or	skills	(24	per	
cent).	But	as	significant	as	either	of	those	was	cultural	resistance	(24	
per	cent)	including	the	fear	of	losing	jobs,	of	changing	work	habits,	
and a general hostility to new technology. Lack of knowledge about 
AI	(19	per	cent)	across	the	news	organisation	along	with	a	lack	of	
strategic	managerial	insight	(17	per	cent)	were	also	key	issues.	They	
also described AI as often expensive to build and manage.
8 716 From our survey it is clear that there is a lack of strategic 
planning. AI strategies will always vary according to the nature 
of the news organisation and what adoption stage they have 
reached, but these are the key elements to consider that have 
emerged from this research:
 • Assess your stage and state of AI readiness 
 •  Understand and categorise the kind of AI technologies  
you are considering 
 •  Decide how AI might relate to your brand and general strategy, 
the problems it might solve, or the needs it could meet
 • Evaluate what areas of your organisation might use AI and why
 •  Identify key obstacles: resources, skills, culture, management, etc 
and plan how to address them in a systematic way
 •  Assign roles and responsibilities and create a communications 
structure across the organisation to include all stakeholders
 •  Establish systems of monitoring and reviewing performance  
and priorities
 •  Create a role for external relations with partners, clients, and 
wider AI resources with a mission to investigate and incorporate 
AI innovation. 
17	 The	majority	of	respondents	had	confidence	that	overall,	the	impact	
would	be	beneficial	if	news	organisations	retained	their	ethical	and	
editorial stance. 
18 The newsrooms identified six key areas where AI is or might  
make a difference to their organisations ethics and editorial 
policy and practice:
 •  Economics: Making cuts from AI-generated savings could lower 
editorial standards. Reinvestments could instead be used to 
improve journalism quality and effectiveness
 •  Algorithmic Bias: Bad	use	of	data	could	lead	to	editorial	
mistakes such as inaccuracy or distortion and even 
discrimination against certain social groups or views 18 The newsrooms identified six key areas where AI is or might 
make a difference to their organisations ethics and editorial 
policy and practice:
 •  Economics: Making cuts from AI-generated savings could 
lower editorial standards. Reinvestments could instead be 
used to improve journalism quality and effectiveness
 •  Algorithmic Bias: Bad	use	of	data	could	lead	to	editorial	
mistakes such as inaccuracy or distortion and even 
discrimination against certain social groups or views 
 •  Misinformation/Filter Bubbles:  AI can help the spread 
of ‘fake news’. Crude use of personalisation can make 
confirmation	bias	or	conflict	worse.	But	well-managed	AI	
can help counter misinformation and improve the quality of 
public information
 •  Enhancement of editorial decisions and transparency: 
AI can help correct old newsroom biases and increase the 
diversity of stories and audiences. It can help promote 
transparency around the use of AI and of journalism in 
general
 •  Balancing human and artificial intelligence: It is vital 
that augmented journalism retains human values and even 
enhances the value of human judgement and creativity 
 •  The role of the technology companies: There is concern 
over	the	power	of	‘Big	Tech’	as	competitors	and	about	their	
control of research and product development. They were 
also seen as a source of innovation, tools, and systems. 
There is a need for more transparency, dialogue, and 
support for journalism from technology companies.8 •  Misinformation/Filter Bubbles:  AI can help the spread of ‘fake 
news’.	Crude	use	of	personalisation	can	make 	confirmation	
bias	or	conflict	worse.	But	well-managed	AI	can	help	counter	
misinformation and improve the quality of public information
 •  Enhancement of editorial decisions and transparency: AI can 
help correct old newsroom biases and increase the diversity of 
stories and audiences. It can help promote transparency around 
the use of AI and of journalism in general
 •  Balancing human and artificial intelligence: It is vital that 
augmented journalism retains human values and even enhances 
the value of human judgement and creativity 
 •  The role of the technology companies: There is concern over 
the	power	of	‘Big	Tech’	as	competitors	and	about	their	control	
of research and product development. They were also seen as 
a source of innovation, tools, and systems. There is a need for 
more transparency, dialogue, and support for journalism from 
technology companies.
19 There were three levels of future thinking:
 •  First: To improve and iterate what is happening now with existing 
product and editorial teams
	 •		Second:	Medium-term	innovation	over	the	next	2-5	years	with	
newer applications
 •  Third: Innovation and experimentation for the long-term that 
might include completely new approaches or structures. 
20 When we asked what would help them meet the challenges of an 
AI future the two most frequent responses had not directly to do 
with the technology:
	 •		44	per	cent	mentioned	training,	education	and	literacy	  
in the newsroom
	 •		43	per	cent	mentioned	the 	need	for	recruiting	people 	 
with new skills.
10 921 The three most common areas for our respondents’ future AI-tool 
wishlist were for:
	 •		More	automatic	tagging/entity	extraction	(newsgathering)
	 •		Better	machine-generated	content	(news	production)
	 •		Better	personalisation/recommendation 	engines	 
(news	distribution).
22 The biggest future wish from respondents was for training  
and education in six different areas:
 •  AI literacy: To spread understanding across the news organisation
 •  AI skills: Basic	skills	such	as	coding	and	understanding 	 
data training 
 •  More advanced AI skills: To foster innovation and as part of 
career development for all staff
 •  For management: To improve general awareness and also 
understanding AI systems and other AI adoption models
 •  Ethics: To understand how to reduce algorithmic or data bias and 
to improve accuracy and reliability
 •  General AI insights: More	scientific	and	social	understanding	of	AI 	
and its impact on users and society.
23 Despite competitive pressures there was a strong interest in 
collaboration to improve standards and innovation. Collaboration 
was suggested:
 •  Across departments within news organisations
	 •		Between	news	organisations	-	on	stories	but	also	on	  
tech development
 •  Across a country but also internationally
 •  With tech companies 
 •  With start-ups and intermediary organisations
 •  With universities/researchers.
1024 AI will re-shape journalism in an incremental way but with longer-
term structural effects that reflect how news media is changing 
for other reasons: technological, social, and commercial. In a 
more networked world AI will become more important in all fields.
25 AI will make news media more ‘unequal’ and diverse and change the 
structure of work, the newsflow, and the relationship with public.
26 AI will power new platforms and tools, such as AR, drones, voice, 
image and text generation, and wearables. 
27 AI will power the way information and debate happens, though often 
not through the news media. Newsrooms will have to adapt to new 
forms of editorial authority and trust.
28 There is much for journalism to learn from other industries, 
including technology companies and start-ups, marketing and 
advertising but also law, gaming, gambling, and music industries: 
How they use the technology, change their workflows, marketing 
practices, their relationship with users, and their ethics.
12 11Introduction  
The Journalism AI Report
Artificial intelligence (AI) is a significant part of journalism already 
but it is unevenly distributed . The technologies that come under the 
umbrella term of AI range from everyday functions such as search, to 
complex algorithms drawing upon deep learning to create text or videos. 
AI technologies are rapidly developing, alongside other radical changes 
in media production and business models. The future impact of AI 
is uncertain but it has the potential for wide-ranging and profound 
influence on how journalism is made and consumed . 
Using AI is not as dramatic a step as when news organisations first 
went online. It has more in common with the adoption of social media 
as a source, production tool, and as a distribution and engagement 
vehicle for journalism. AI has the potential to enhance journalism 
throughout the process in significant ways that may, over the next 
few years, have structural effects. However, even the newsrooms we 
surveyed that are furthest ahead in the adoption of AI described it as 
additional, supplementary and catalytic, not yet transformational.
When fully integrated, pervasive, and operating at scale, AI could 
have high value in certain areas such as audience engagement, story 
discovery, and labour efficiency. Some of the possible uses, such as 
automated translation and text generation, may enable leaps forward 
into new areas of journalism, marketing and product development. 
But overall, our respondents, while often enthusiastic, 
said that they don’t expect an immediate revolution at 
scale through AI, compared to the advances that might 
occur in other fields such as security, retail, or health. 
This is partly because of the special nature and needs 
of journalism but also because of the relative lack of 
resources for research and development.
12The power and potential described in this report makes it clear that 
all newsrooms should pay attention to AI . The world that journalism 
inhabits, especially the media and technology fields, will be reshaped 
by AI. If journalism wants to stay at the cutting edge, it needs to inform 
itself about AI and explore its uses and consequences for the newsroom 
as well as wider society. Most of our respondents are still at an early 
stage of AI adoption, some are deliberately exercising caution in their 
approach. But very few denied that it would play a significant part in 
their future and that of the industry as a whole.
We include our own analysis but for wider context and more detailed 
insights we recommend further readings in the appendices. There are 
links to case studies in the endnotes. 
This report should be read as an introduction to and discussion of 
journalism and AI. We hope it will help newsrooms make decisions 
around strategy, but it is not a manual for implementation . We hope 
that further research, training, and a network will emerge from this 
process, to follow up on the issues raised by this report and dive deeper 
into specifics. Please get in touch if you want to be part of that process. 
You’ll find the contacts at the end of this report.
The Introduction  that follows deals with how the newsrooms defined 
artificial intelligence as an idea and as a practice. 
Chapter One  deals with what is happening now: How are newsrooms 
using AI, and what are their motives for using it? What works and what 
doesn’t, so far? 
Chapter Two looks at strategy: How do newsrooms do this? What kind 
of approaches to AI are taken by news organisations? What impact can 
AI have, and what are the key challenges? 
Chapter Three looks at ethics and editorial policy: What difference does 
AI make? What positive and negative effects does it have on the quality 
of journalism? What issues are raised around bias or accountability? 
What about the role of the technology companies? 
14 13Chapter Four  looks at the role of AI in the future of journalism: What 
is going to happen next and where will this lead? What uses of AI do 
newsrooms aspire to? What kind of skills, roles, training, and education do 
we need in the future? What is the role of collaboration? How will AI shape 
the way that journalism is going to evolve as a practice and a business? 
The Conclusion  sets out the author’s view, based on the survey, of 
how the news industry should move forward and the challenges and 
opportunities AI presents.
The Executive Summary gives the main points of the report. At the end 
of it, you can find a glossary, endnotes, and a list of suggested readings 
and resources. 
This work was funded by the Google News Initiative2 and carried 
out by a team led by Professor Charlie Beckett, director of the LSE’s 
international journalism think-tank, Polis .3 
We would like to thank all the journalists, technologists, and researchers 
who took part in the project. Their enthusiastic efforts to help us 
demonstrated an impressive commitment to their work and to the value 
of journalism and its challenging future. The project was managed by 
Mattia Peretti and the lead researcher was Fabio Chiusi. 
14Newsroom Definitions of Artificial Intelligence
Before we see what our survey respondents said about AI, it is useful to 
understand what they mean by the term. Artificial General Intelligence 
(AGI) does not exist operationally, it is still a hypothesis.4 Machines 
can’t think entirely for themselves like the Hal computer in 2001 Space 
Odyssey . ‘General’ or ‘strong’ AI is still years away and might never 
be reached at all. AI as it is used today in news and other industries 
is defined as ‘narrow’, or ‘weak’ AI, a set of far more limited functions 
that are programmed.5 They may well be faster or more effective than 
humans but in reality this is ‘machine learning’ (ML) or ‘natural language 
processing’ (NLP). Many processes described as AI often incorporate 
more conventional technologies. These are systems that are created or 
‘trained’ by humans. Some are responsive and adaptable but can often 
carry out quite simple automation or data-processing tasks.
Artificial intelligence, machine 
learning, natural language 
processing… Is your head spinning 
already? We got you covered. Look 
for definitions in the Glossary  at 
the end of this report.
16 15Artificial intelligence is a collection of ideas, 
technologies, and techniques that relate to a 
computer system’s capacity to perform tasks 
normally requiring human intelligence.6
We will use ‘AI’ as an umbrella term, always accepting that it refers to a 
portmanteau of related technologies.7 AI is driven by algorithms, “a series 
of steps that is undertaken in order to solve a particular problem or to 
accomplish a defined outcome”.8 These can be programmed as machine 
learning or automation. They may be manifested as tools such as ‘bots’. 
The key factor is the degree of autonomy and adaptivity they have and this 
is on a spectrum.9 At one extreme “the computer decides everything, acts 
autonomously, ignoring the human”. At the lower end the “computer offers 
a complete set of decision/action alternatives” for humans to act upon.10
There are three fields of operation for AI, covering almost all of the 
journalistic process: newsgathering, production, and distribution. We first 
asked our participants what kind of operational definition of ‘artificial 
intelligence’ they use. Their definitions reflect the complexity of the topic 
and the variety of approaches. Definitions partly reflect the respondent’s 
understanding but also the motive for engaging with this technology. 
While some people had an objective or scientific definition, most related 
their definition of the technology to its use and purpose. This was 
invariably as additional to existing, human centred practice: ‘augmented 
journalism’. Sometimes the term was used in a very specific way, for 
example, to describe a tool to analyse data sets such as court records 
for an investigation. In other uses it means something more systematic, 
such as continuous personalisation of content for users through 
audience data. For this report we borrowed a simple definition:
16The way that newsrooms defined AI for this survey usually reflected 
its role in their organisations. These were generally working definitions 
used to communicate with colleagues, the public, or partners. A broader 
understanding of AI in journalism would need to take into account the views 
of those stakeholders, too. Our respondents’ replies divided broadly into 
technological and human- or task-related categories.
Technological definitions were based on ideas around algorithms, natural 
language processing, automation, and data analysis. For about a third of 
respondents, ‘machine learning’ was the key term: 
Technically, I take it to mean machine learning/neural 
network-driven systems, but for the purposes of newsroom 
technology I think of it more as any system of automation that’s 
more than a very simple tool.  
Respondents recognised that their definitions could not be final, 
considering the fast-evolving nature of the technology. More concrete 
ideas were sought, partly to distance their definitions from the hype 
around the term ‘artificial intelligence’:
Usually, we don’t use this term at all. We are using more 
narrow names like ‘machine learning’, or when we speak about 
some specific field we are using terms like NLP [Natural 
Language Processing] or deep learning. ‘AI’ feels like a 
buzzword for us.  
These more technological definitions stressed the way that AI works. For 
example, by creating pattern recognition in managing large sets of data, 
or the principle of prediction and classification.
The human- or task-related definitional approach sees AI as the ability 
to perform, replicate, or mimic tasks commonly associated with human 
beings’ cognitive abilities, or ‘human intelligence’. Usually they are related 
to the journalists but also the audience. Almost always AI is defined as 
there to augment or expand human capabilities: 
18 17Using computing power to solve data-based problems and do 
analysis not achievable by human power – either by learning/self-
improving or by processing and analyzing vast amounts of data.  
Our respondents were all working in or with newsrooms rather than 
in pure research, so not surprisingly in nearly all cases there was a 
functional, problem-solving aspect to their definitions. At times, elements 
from different definitions combine to conform to Nick Diakopoulos’ idea 
of hybridised AI journalism: “We see AI broadly as technology that can 
acquire, understand and make conclusions from information, and then 
learn from its decisions”.11 
A quarter of our respondents said that their organisation does not have a 
formal definition of AI or are in the process of creating one: 
We don’t have one. We have a debate on this subject.  
The BBC  is an interesting exception. Perhaps because of its scale and 
the variety of its operations, it deploys multiple definitions:
The BBC doesn’t have a single specific definition of artificial 
intelligence. The term is used to mean different things by different 
people, and is often used to refer generally to the frontier of 
advanced technology. Some common things that people mean by 
the term ‘artificial intelligence’ at the BBC are (1) technologies 
based on machine learning of any kind (especially neural 
networks), (2) technologies that are represented as intelligent 
agents (eg, voice agents, chat bots), (3) technologies that 
automate tasks that previously required people to do 
(eg, writing articles using NLG [Natural 
Language Generation], automated 
translation or transcription, etc). Products 
that use ‘artificial intelligence’ sometimes 
fit in all three of these categories.  
18The definition matters because it reflects how a newsroom might think 
about its AI strategy [See also Chapter Two] . Having a definition of some 
sort is a useful first step to help think about how it differs from other 
technologies. It reflects the levels of AI literacy in the organisation and 
the ability to communicate with colleagues as well as externally. One 
of the core tensions around the adoption of any new technology in the 
newsroom is the culture clash involved between tech specialists and 
other departments. How the news organisation defines AI may help 
towards clarifying roles. 
As the technology advances, newsrooms will increasingly have AI that 
performs more systematic and autonomous functions. Understanding 
what AI is will be important to realising its potential and the 
opportunities and risks involved. However, newsrooms are highly diverse 
and so is AI. The technology and its uses are continually evolving so the 
definition will also change. A degree of flexibility in its definition reflects 
the complex reality of the technology and its applications. 
20 19Chapter 1  
How AI is Being Used  
in Journalism Today
1.0 What Newsrooms are Doing and Why
We asked newsrooms what AI they were using, why they used it and 
what worked. The replies split broadly into three areas:
•  Newsgathering:  sourcing of information, story idea generation, 
identifying trends, investigations, event or issue monitoring, 
extracting information or content.
•  News production:  content creation, editing, packaging for different 
formats and platforms, text, image and video creation, repurposing 
content for different audiences.
•  News distribution:  personalisation, marketing, finding audiences, 
understanding user behaviour, monetisation/subscriptions.
Just under half of respondents said they used AI for newsgathering, two-
thirds for production and just over half for distribution. But in the context 
of contemporary ‘networked’12 or ‘hybrid’13 journalism, that traditional 
divide between input and output is better understood as a highly-
interrelated process. 
One of the key aspects of AI and journalism  [as we shall explore 
in Chapter Two]  is that it allows the whole journalism model 
to become more holistic, with a feedback loop between 
the different parts of the production and dissemination 
process. The moderation of user comments, for example, 
could be seen as a way of gathering content, creating 
or editing that content and as a key way of increasing 
audience engagement. Here is an example of one 
newsroom doing just about everything:
20Recommendation of related articles. Robot journalism (eg, for 
lower league football matches). Personalization of the newsfeed. 
Lookalike audiences based on user data to increase CPMs. Predictive 
analytics to optimize news curation. Speech-to-text services to increase 
our editors’ productivity. Churn prediction and prediction of the 
propensity to subscribe. Tagging/entity recognition. Spell check.  
As discussed in the introduction, the AI used would usually be better 
described more specifically as forms, for example, of machine learning, 
automation, and data processing. Some of the processes that come under 
the ‘AI’ label may be quite limited in their ‘AI-ness’. Inevitably there is some 
confusion and grey areas. Journalism continues to undergo a thorough 
process of reform and innovation and it is not always clear where a particular 
technology has an impact, or the boundaries of its influence.
Under-pinning all AI processes is data: data about audiences such as 
their behaviour; data about the reported subject such as official records; 
data about the journalism such as sentiment and language. Whatever the 
precise category, it is clear that the use of AI is permeating newsflows. That 
makes it harder to identify and evaluate what it does, but it also reflects the 
adaptability of the technology and its increasing integration into operations. 
Thoughts from our respondents about how AI could improve their work 
grouped around ideas of being more competitive, efficient and time-saving. 
But the dominant motive was connecting better created content more 
effectively to audiences, who in turn would be more engaged and prepared 
to pay attention, or money, for journalism. There were also some specialised 
functions such as dealing with misinformation and verification. The overall 
aim was characterised by a general aspiration to use any efficiencies to free 
up resources for enhanced newsroom functionality and for new or improved 
content and services. Also driving respondents’ motivations was the need to 
keep up with technological and market changes. [See the next two chapters 
for how that fits into wider planning] . Results were described as mixed and 
often still provisional, but overall there was a sense that AI is gaining a 
significant role and proving worthwhile.
22 211.1 Newsgathering
Newsgathering related to AI is part of a data-driven production cycle. 
AI can help gather material but it is also tasked with helping editorial to 
assess what will interest users:
For our editorial products we focus more on supporting our 
editorial teams in their editorial decisions without replacing those 
decision processes. One main area we focus on is to make 
information accessible: we ingest a lot of video content every day. 
We want to help journalists to work with this flood of 
information to help in deciding which information is most 
relevant for the audience.  
AI can help with the job of sifting through content from official sources 
but also from the public and social media, for example through the 
automated filtering of UGC (User Generated Content). AI programmes 
can categorise information or material at scale for different purposes:
Image recognition APIs [Application Programme Interfaces] 
for analytics and journalism – genders and ages in images, 
genders in text.  
Neural Networks for photo tagging and Natural Language 
sentiment (Google Cloud APIs).  
For the AI to work, it has to treat material as data and that means that 
the process of tagging that data or ‘metadata’ is critical. AI allows that to 
be automated to some degree. It is difficult to implement thoroughly but 
it underpins everything else:
We built an automated tagger for our newspaper’s articles 
(which tags articles with topics/keywords – formerly done by 
editors), built into our CMS [Content Management System].  
AI helps the newsroom to make decisions about how this raw material 
becomes content:
We have an internal tool that combines data analysis and 
language generation systems to write all or parts of stories and to 
alert journalists to potentially interesting patterns in data.  
22Story discovery is also made possible by machine learning algorithms that 
help journalists spot trends and facts that could otherwise remain hidden 
from human eyes: 
We needed to find a news archive with the largest possible number 
of publications in Mexico so we could track daily coverage across the 
country. Google News’ vast collection of local and national news 
stories across Mexico was a good fit. The effort required us to identify 
the difference between the number of homicides officially recorded and 
the news stories of those killings on Google News. This required 
machine learning algorithms that were able to identify the first 
reported story and then pinpoint where the event took place. With 
that information, we were able to connect reported events by media 
with the government’s reports on homicides across more than 2400 
municipalities in Mexico.  14
1.2 News Production
AI can be a newsroom tool that helps with the process of content creation at 
a granular level:
Our sub-editors and journalists currently use Grammarly, which 
employs artificial intelligence techniques, to help check grammar and 
spelling for our English articles.  
We have started using AI for general articles, we tried AI Writer 
together with Deepl.com for translation duties.  
But even the most basic routine deployment of AI is always part of the 
data cycle process that enriches the journalism production with virtuous 
feedback loops:
We employ entity extraction tools that separate different types of 
entities and present them to the journalists during the article creation 
process. This improves the quality of the tagging we employ. We also 
use it in our internal news tracking tools. As we are pulling 
hundreds of thousands of articles from all over the world, it’s 
imperative for us to enrich the metadata of each and cluster them. 
Entity extraction gives us critical informational nuggets that can be 
used in further processing to display global trends.  
24 23Another important AI function is for verification, either as a support 
for building the credibility of content in a routine way or as a specialist 
function in itself. Initiatives such as Chequeado15 and Full Fact16 employ 
machine learning-powered tools for automated fact-checking:
Claim detection: We use machine learning to help us separate 
claims from other sentences. This helps our fact checkers in deciding 
what to check each day. Robochecking is automatically checking 
claims against databases of information. We use the Office for 
National Statistics data to check claims in real-time. For example, if 
someone says “Employment has fallen by 10 per cent since 2016” 
our system finds the correct numbers and generates a graph, and 
answer, in real-time. Claim matching: This is the ability to find 
claims we have already checked, in new places. We therefore need the 
ability to match a claim to a new sentence.  
As misinformation exploits new technologies and continues to operate 
at scale, this will be a key growth area for newsrooms, such as the 
detection of ‘deep fakes’.  Speech-to-text, automatic translation, image 
recognition, video-making, and narrative text generation are all rapidly 
evolving uses:17
Our archives are using AI for automatic tagging of content by 
automatically extracting keywords, topics, entities like persons and 
places. They are building their own training data set by using a face 
recognition algorithm to tag faces in news videos with the aim to 
build up a tagged data set with regional politicians that are usually 
not recognized by trained face recognition software. The archives are 
also using speech to text algorithms for creating subtitles. As dialect 
recognition is an issue, the archives have started a dialect 
recognition project by training an algorithm with dialect data.  
This way of organising material through AI enables automated content 
creation, often for social media:
We use an algorithm for our posts on social media. Starting from 
RSS feeds or from email, it can write posts on Facebook and tweets. 
It manipulates the text, publishes updates at scheduled times, sends 
emails and reminders for our cross postings.  
24Finnish public service broadcaster Yle is confident enough in the 
technology to have built its own robot journalist:18
Voitto ‘robot journalist’ is today producing hundreds of pieces of 
content in a week (textual content and illustrations). Voitto produces 
tailored content for the news app as well as for various newsletters 
and several Twitter accounts. Voitto combines rule-based methods as 
well as early experiments with ML. 
AI can enhance user information around an event, such as during Sky 
News ’ recent live Royal Wedding coverage that used facial recognition 
technology to identify celebrities arriving at the ceremony.19 
A project from Le Monde  highlights how AI can further impact content 
creation at local level during an election:20
In 2015, we worked with Syllabs to automatize election reports. 
The French electoral map is made of approx 36000 cities, we can’t 
write pieces for each of those units. Robots will. We got structured 
data from the French Home Office. This data was analyzed and 
managed by Syllabs’ machines which created approx 36000 pieces 
displayed on 36000 pages where we displayed database information 
such as population, location, mayor, previous elections results, 
wealth, employment rate, etc. 
Another respondent pointed to the “automatic creation and publishing” 
not just “of soccer match commentaries”, but also of “traffic accidents 
and weather forecasts”. Experiments with automation involve the creation 
of headlines and summaries of press releases.21 
AI is used for routine, commodity journalism22 but it can also be 
combined with human journalists to tailor mass data sets to specific 
audiences. The Press Association ’s ‘RADAR’ (‘Reporters And Data And 
Robots’) news service23 combines humans and machines to create 
localised stories at scale on topics such as “crime figures, hospital 
waiting times and pupil absences from school”. 
26 25The Guardian ’s ‘ReporterMate’ tool, is another example of this 
‘augmented journalism’ that combines AI with humans:24
A robotic system that allows journalists to build simple templates 
to fit specific data sets. ReporterMate’s first article, on political 
donations, was based on data from the Australian Electoral 
Commission and was published in January 2019.  
AI is helping facilitate new forms of journalism, though for many of our 
respondents these were still in development [See also Chapter Four] :
We’re also experimenting with new journalistic forms. 
Experiments with automated systems allow us to combine 
different kinds of data-powered storytelling methods (eg, one that 
allows you to follow individual parliament members). AI-powered 
experiments have also enabled us to create immersive content 
experiences in which the user can directly affect and personalise 
the content experience itself.  
A lot of the editorial functions cited were related to investigative 
journalism that could not be done by humans alone:25 
We used AI to analyze a trove of Housing and Urban 
Development inspection pictures to identify concentrations of 
problems (such as mold, missing smoke detectors, etc.) at various 
housing complexes, which isn’t otherwise possible without lots of 
FOIA [Freedom of Information Act] requests.  
AI can also add depth to general journalism:
We are using it to solve some specific tasks in our reporting. 
So, for example, we used Deep Learning Model (ResNet) to 
search for places of illegal mining on hundred of thousands of 
images.26 Also we used Deep Learning (ULMFit based model) for 
Natural Language Processing (NLP) to process millions of news 
items to search for manipulative content; and Machine Learning 
to create a map of different topics.27 We used Machine Learning 
in a couple of other projects with data from social networks such 
as sentiment analysis for Twitter messages.   28
26These investigative tools increase efficiency, enabling hard-pressed 
newsrooms to cope with the research labour involved, but they also reveal 
information that might otherwise be missed by human-only analysis:
‘Laundrette’ is a tool that structures Freedom of Information 
requests and is already in the hands of the data journalism team, 
saving hours or work. ‘Giant’ identifies patterns in data that 
otherwise we might never see. For instance, we can link disparate 
emails from different inboxes into threads. We can automatically 
search for terms that we have identified with watchlists.  
As we will see in section 4.3 on collaboration, newsrooms are often 
working with external partners on AI. Third-party organisations have vital 
specialist technical knowledge:
We have done one major analytics project in investigative 
journalism in collaboration with the Norwegian University  
of Science and Technology where we used advanced analytics 
tools to analyze manipulation of streaming figures in Jay 
Z-owned Tidal.   29
We are using machine learning systems in our journalistic 
investigations. These include fast.ai, Google’s AutoML, 
Dialogflow NLP.  
Or newsrooms can scale up the value and share the costs of AI with 
other newsrooms:
We have partnered with four major news organizations on 
projects currently underway, with publication expected in the 
coming weeks.  
As part of the ICIJ [International Consortium of Investigative 
Journalists] we also contributed to the leak search engine.   30
28
 27Not only can AI enable fresh investigations but it also allows the newsroom 
to follow up on the story in real time and keep track of how it develops:
We used machine learning to automate how journalists can find 
ways to track political funding and other disclosures by listed 
corporates in the absence of enabling legislative framework for 
transparency. We continue to work with Stanford computer scientists 
to find ways we can use open source code to automate alerts and 
make it easier for journalists to get notified through an email alert 
whenever there is new information on campaign funding.  
Increasingly, innovation is supported by external sources  
such as foundations:
Under a pilot grant from the Knight Foundation, we are actively 
helping both our journalists and journalists at other news 
organizations. For example, we used machine learning techniques 
for a story about unique risk factors Lyft included in their IPO fling. 
We identified patterns in police helicopter flight data that could let 
local newsrooms know, in real time, whether something big is 
happening they don’t know about.   31
1.3 News Distribution
With AI-networked journalism there is not always a clear distinction between 
content creation and consumption. As mentioned above, an example is 
AI-powered comment moderation. It adds content but is also a vital way to 
engage readers. Human moderation of user comments was laborious but 
AI tools can reduce the toxicity and promote more engaging interactions:
Three years ago, [we created] a very simple but impactful tool that 
allows moderators to maintain a watchlist of key terms, stalls the 
publication of any comment mentioning them and alerts our 
moderators. Our developers used machine learning techniques on our 
existing body of moderated comments to build a model that classifies 
comments as good or bad. 22 per cent of comments that are flagged as 
bad are subsequently blocked – a much better rate than for abuse-
reports from users. Only 0.3 per cent of comments identified as good 
are subsequently reported/blocked, a very high level of accuracy.  
28
What users do with content – measured as engagement, shares, 
comments, pageviews, and time on page – can help inform content 
strategy. The Times of London  spent three months using machine learning 
to relate 10 user metrics to 16 different pieces of content metadata such as 
headlines and article format to understand what worked best for readers.32 
The results led to changes in the amount and type of content created 
for certain sections or platforms and a sharpened focus on boosting 
engagement. For example, which stories to promote via social media. It 
made their content creation strategy more efficient and in terms of reader 
attention and subscription renewal, more effective.  
Many newsrooms reported that they were adopting this more holistic 
personalisation approach with AI technologies to improve the quality of the 
user experience: 
All of our websites include personalized recommendations of 
some sort. The homepage of our biggest site is about 50 per cent 
personalized. That personalization system uses real time data to 
recommend articles to users based on various factors. It uses 
some machine learning algorithms, such as collaborative 
filtering, to score articles. However, the system also has some 
simple rules. For example, an article will receive a lower score 
(and therefore appear further down on the page) the more times 
a user has already seen it. We use this technology to recommend 
content, as well as to deliver personalized campaigns (offers to 
buy subscriptions), and to decide when content marketing should 
appear for a user. In the near future, we will start personalizing 
and automating push notifications and newsletters.  
Every newsroom has a different model for its relationship with the user, 
and for some of them AI processes can be limited:
I’ve only seen recommendation applications that were not 
super inspiring, to be totally honest. It’s very much focused on 
engagement rather than servicing the user.  
30
 29But personalisation of content can work even when users think they 
don’t want it:
Our users don’t show a lot of acceptance of personalized news 
products yet. Either they don’t see the value of personalized lists 
or they don’t want their news experience to be personalized. But 
in tests engagement increased over human-curated feeds.  
Some newsrooms were taking personalisation onto new distribution 
channels such as audio and newsletters:
Our algorithms deliver audio content, tailoring it to users 
based on actions they take (listening all the way through to a 
story, skipping, sharing on social), combined with human 
curation. Through the combination of personalization algorithms 
and editorial choices, we have been able to optimize listening 
times on digital platforms that extend far beyond average 
listening times on terrestrial broadcast radio.  
AI allows the automated creation and tailoring of content to different 
audience segments.  This has an impact on both the audience 
experience and content production. But the intended outcome is 
engagement that supports business models such as paywalls and 
subscription. Larger organisations such as the Times of London  and 
The New York Times  have adopted sophisticated AI-driven systems, but 
smaller publishers also report higher conversion rates with ‘smarter, 
dynamic paygates’ that deploy a range of AI uses:33 
Personalising marketing communications recommendations 
for topics of content automated curation of index/topic pages; 
making predictions about the relative potential for success of a 
story; to allow newsroom to make relevant promotional decision 
(Promotional Index); making predictions about optimal tagging 
(Discoverability Index); Topic tracker (tool that serves 
personalized further reading recommendations with a gamified 
incentive to read).  
Even when automating journalism our respondents agree that, however 
efficient the algorithms might be, human judgement remains vital in 
planning, executing, and monitoring these processes.
30
THE FUTURE IS ALREADY HERE
A selection of AI applications admired by our respondents:
1 – The Wall Street Journal’s dynamic paywall: 34
Machine learning-informed subscription decisions “to show different visitors, who have 
different likelihoods of subscribing, different levels of access to its site”. 
2 – The Washington Post’s Heliograf: 35
A robo-reporting tool successfully adopted, for example, in reporting on the 2016 
summer Olympics and congressional races on Election Day.
3 – The Press Association’s RADAR: 36
An automated news service set up by the Press Association and Urbs Media “to write 
local news stories at a frequency and precision impossible otherwise” – 50.000 in the 
first three months.
4 – The Times of London’s JAMES: 37
Acronym for ‘ Journey Automated Messaging for higher Engagement through Self-
Learning’, it “uses data to get to know the habits, interests, and preferences of readers, 
acting as a digital butler.”
5 – Bloomberg’s Cyborg: 38,39
An automated system that uses AI and extraction to identify key data points in earnings 
reports for thousands of companies and publish headlines and articles in seconds.
6 – ByteDance’s Toutiao: 40
Chinese mobile app using AI-powered personalisation engines “to source and curate 
daily news and articles for users via its 4000 partner sites”. 
7 – DeepL: 41
A company that builds deep learning-powered tools to understand and automatically 
translate texts.
8 – The New York Times’s Project Feels: 42
“A project to understand and predict the emotional impact of Times articles”, and then 
serve personalised ads accordingly.
9 – Texty’s Leprosy of the Land: 43
A piece of investigative journalism made possible by a “machine learning model” to find 
traces of illegal amber mining in Ukraine.
10 – Yle’s Voitto: 44
A smart news assistant that “ensures that you don’t miss the news you want to read” by 
giving “smart news recommendations using notifications on your lock screen”.
32
 311.4 Why Newsrooms Use AI
We can see that there is a wealth of activity and development happening, 
but why? There were three core reasons given by our respondents:
WHY HAVE YOU STARTED ADOPTING AI TECHNOLOGIES?
To make journalists’  
work more efficient
To deliver more relevant 
content to users
To improve business 
efficiencyTo make journalists’  
work more efficient
To deliver more relevant 
content to users
To improve business 
efficiency
0% 25% 50% 75% 100%
68%
45%
20%
NB: Proportion of respondents who mentioned each motivation in their answers.
As we will see in Chapter Two, there were a range of approaches to AI 
adoption. A small minority had specific AI plans, while the majority wer e 
pursuing a more ad hoc approach. A minority of news organisations had 
sole objectives. Some were specialists so might focus on one aspect 
such as investigative journalism. Others were at an early stage and so 
had only implemented a limited range of projects with a narrow focus 
on one goal such as personalisation. But the majority had a range of 
motives and a significant number had a holistic approach:
The aim: augment the user-citizen, journalist, and the 
newsroom. And to create feedback loops that help us understand 
our users, content and our journalistic actions and the world 
around us in relation to each other. We aim to provide a more 
direct, meaningful, and engaging experiences in our main 
services. We aim to empower journalists in their news reporting 
and storytelling. And we want to create new methods and tools to 
better understand ourselves and the world around us.  
32
1.3 News Distribution
The complexity of the technology is a practical and psychological brake, 
although another restraint seems to be the overload of newsroom 
development already occurring. Our respondents were generally tech 
early-adopters so not surprisingly the overall tone was positive. While 
there were fears of missing out, the predominant mood was pragmatic. 
The core goal was to improve the existing product and that means to 
support the journalist:
We believe that, in a world where resources are increasingly tight, 
we need to support journalists by reducing the amount of grunt 
work they need to do and improve the journalism by allowing them 
to focus on what really matters and what they do best.  
Most respondents characterised the benefits of  
“simpler workflows, cost-cutting through automation, 
greater productivity” as ways to enable better work,  
not to cut costs:
Increased capability for investigations by looking 
at big data sets.  
To be faster in finding news.  
To improve fact-checking / fight disinformation.  
But they also saw AI in the economic context where news 
organisations are not just competing with each other. They are fighting 
for attention and revenue with everything else online. AI is seen as a 
potential catalyst for renewal and to avoid being left behind:
The media industry is undergoing a crisis and every measure 
that might provide a competitive advantage must be taken.  
News without technology can’t survive in the digital era.  
They recognised that other industries are adopting AI and so must  
the next generation news media [See Chapter Four for lessons from 
other industries] :
34
 331.3 News Distribution
Advances in machine-learning algorithms have empowered 
banks, retailers, finance firms, law enforcement, social media 
companies, and so many more. And while we can (and should) 
debate how these industries use AI, there’s no dispute about the 
power these methods provide their practitioners. Now, in the same 
way spreadsheets, databases, and mapping programs have 
moved into the newsroom, machine learning methods are 
becoming accessible to motivated journalists – allowing them to 
use that power for their reporting into stories that would 
otherwise be difficult or even impossible. This is the next 
generation of data journalism.  
As we will see in Chapters Two and Three, this is primarily about 
additionality or replacement of existing products and processes but 
cumulatively it becomes a structural question for journalists.
1.5 What is Working and What is Not
The outcome of technological innovation in the newsroom is always 
unpredictable. The process of adoption is iterative and subject to the 
exigencies of the real-world news environment. Different tools will be 
subject to different measures of success. Though, as we will see in 
Chapter Two, there are some common approaches that can be useful to 
newsrooms. For many of our respondents it is just too early to tell:
Most applications are still in nascent form and their success 
or failure is still uncertain. This is particularly true of products 
based on intelligent agents in voice and chat environments.  
For some there were clear failures, or they realised that AI was not the 
right solution for a particular problem:
We experienced multiple failures in AI.  
Most of our innovative applications that succeed aren’t based 
on artificial intelligence.  
34
It is difficult to generalise about failures but they tended to be related 
to either complex or emergent processes that were not relatable to 
newsroom needs:
The NLP [Natural Language Processing] systems currently 
available to the news industry are not fit for purpose. Third-
party NLP protocols do not provide signals that meet human 
editorial standards. There is an urgent need for the news 
business to develop a common approach to NLP as a tool for use 
in personalisation and content recommender systems. 
Some use-cases are innately tough: such as getting the public to hand 
over their money, or fact-checking complex claims. Some of the most 
clear-cut successes tended to be specific tasks with clear objectives. 
This is a fairly typical list:
1)  object extraction/automated tagging (it shone light to the 
metaphorical dark cave which is comprised of our 
untagged assets); 
 2)   automated fact-checking (claim detection and 
robochecking, very promising);
 3)  content (pre)moderation; 
 4)   speech-to-text (English mostly, though; other languages 
would still file under failure); 
 5) ad targeting tools; 
 6) propensity models; 
 7)  machine-generated content.  
Just because something didn’t work immediately did not mean that our 
digitally-enthusiastic respondents gave up:
We think it’s important to keep testing and working on this, 
creating transparency about how our personalization works, 
giving users control over personalization. We’re testing what we 
call ‘trust features’ to increase acceptance and getting the mix 
between human curated and machine curated lists right. 
36
 35We take a MVP [Minimum Viable Product] start-up mindset 
when it comes to AI. Essentially, this means launching an early 
version of tools, getting feedback from its users, then rolling out 
new features and functionality, and then iterating on this 
feedback continuously. While AI may not solve every problem or 
challenge, we are big believers in creative innovation and think 
that AI-driven tools can help complement our content creation, 
advertising, and marketing efforts in meaningful ways.  
While some newsrooms were able to experiment with a range of tools or 
products, most tried to concentrate on a few:
Trying to do too much usually results in something that fails 
at everything.  
As we will see in Chapter Two, part of the problem is defining ‘success’. 
What works is not necessarily what is needed. The effort to adopt AI 
shown by our respondents is a powerful answer to those who accuse 
the news media of a lack of appetite for innovation:
It depends on how you define success. We’ve learned a lot 
from every single thing we’ve tried.  
36
2.0 The Need for Strategy
The introduction of new technologies in media is sometimes 
characterised by a romantic rhetoric of creative ‘disruption’. Yet 
generally newsrooms do not have the time or resources to allow for 
free-wheeling risky adventures.  In practice, even the most flamboyant 
of VC-funded start-ups needs to have a strategy if new ideas are to be 
translated into sustainable added value at significant scale. Strategies 
have to be flexible but there needs to be a structure to frame the 
investment of energy, time and money. When it involves innovation that 
may have structural impacts on newsroom development it becomes 
even more important that it relates to the overarching longer-term 
strategy of the organisation. Measurements of progress such as KPIs 
are needed to track impact.
Mass, effective application of AI is new so most organisations will 
not be AI-ready. They will have to build their knowledge, skills and, as 
data scientist Monica Rogati says in her AI Hierarchy of Needs, “the 
infrastructure to implement (and reap the benefits of) the most basic data 
science  algorithms and operations, …[and]... machine learning .”45 Any AI 
strategy has to reflect these imperatives of AI-adoption. It has to have a 
diagnosis of the current situation, a vision 
of where you are trying to get to and an 
outline of coherent actions to get there.46  Chapter 2  
AI Strategy
38 37As our survey showed, how this happens may vary from a general plan to 
a much more detailed operational timetable and assessment procedure. 
In response to technological and market developments over the last two 
decades most news organisations have evolved business and production 
strategies. This idea of developing ‘strategy’ was something of a novelty for 
news organisations used to business models and technologies that had 
been fundamentally unchanged for half a century. Going online, being digital 
first, and building new business models based on subscriptions, paywalls, 
or memberships are all structural strategic responses. All have significant 
implications for workflows and audience relations. Within the overall 
strategy will be sub-strategies for specifics such as platforms, e-commerce, 
or content production. How do newsrooms strategise AI?
We took a qualitative approach to this part of our survey because it is 
crucial to understand what news organisations are thinking as well as 
doing. According to editorial technology strategist Francesco Marconi they 
might start by thinking like this: 47
Challenge: What challenges are you trying to solve?
Process: How can you translate this challenge into practical steps? 
Data: Do you have the right data to solve the challenge?
Research: Where is the data coming from and how is it going to be vetted?
Pitfalls:  What errors can be expected from the algorithm and how can  
you add oversight?
In response to those questions, Marconi’s Wall Street Journal,  for example, 
now has a sophisticated, holistic strategy that seeks to place AI-related 
technologies within a wider innovation infrastructure.48 
This report does not set out in detail how to create a strategy. There are 
more technical resources in the recommended readings at the end of this 
report. Our aim is to use the responses from the newsrooms we surveyed 
to suggest the different elements that have to be addressed, the kind of 
challenges that will be faced, and the priorities that need to be set.
382.1 News Organisations’ AI Strategies
Just over a third of our respondents claimed to have an active AI 
strategy, two-thirds said they did not. This appears to be consistent  
with the high level of experimentation found in previous answers around  
the success or failure of current journalism initiatives involving AI  
[See Chapter One] . 
DOES YOUR ORGANISATION HAVE A STRATEGY FOR AI?
37%
63%   37% have an AI strategy
   63% dont have an AI strategy
Where there is an overt AI strategy it is usually the domain of the data/tech/
digital/innovation team: 
The Data department is the one where all the AI-related 
initiatives converge; they will gather requirements from the rest of the 
areas of the company and set the roadmap for implementation.  
In one instance, responsibility lies with the Strategy Office. In another, 
with the Product team. One respondent said that “it is lead by the digital 
newsroom, involving different parts of the organization based on the 
relevant project”. So rather than a general strategy there were department-
or team-level AI initiatives. Other organisations said that the responsibility 
for AI is entirely dispersed:
The AI strategies are shared across the newsroom, technology, 
data science and product teams.   
40 39Sometimes the AI work is ring-fenced in a unit that is deliberately not 
subjected to the constraints of the wider organisation: 
We have set down the team involved with AI as a separate 
incubator. Such a new thing as AI does not match current IT. 
Only by being independent, we are able to gain traction.  
WHAT DEPARTMENT OF YOUR NEWSROOM LEAD ON AI STRATEGY?
30%
22% 16%13%19%   A dedicated cross-functional team 
was designed to focus specifically 
on AI strategy 
   Strategy led by Innovation/  
Digital teams 
   Strategy led by Data teams
   Strategy led by Tech/IT departments 
   Strategy led by other departments, 
incl. Product, Business, Editorial  
NB: Only the responses of newsrooms that said to have an AI strategy were considered.
Many respondents reported confusion around roles and responsibilities. 
Several respondents argued that at early stage adoption for AI it is better to 
have a series of approaches related to different AI applications, rather than 
a formal, overarching strategy:
Since the applications of AI-related tools are quite diverse, it 
would seem reasonable to set up several strategies – one for in-
house developments in the field of automation, one for the 
implementation of tools in internal workflows, one for automated 
recommendations... So far, there are different departments 
involved: the newsroom, in particular the editorial R&D team, 
the data journalism department, the social media department, 
IT and marketing experts, product development teams. 
40That more plural approach was also reflected by a few respondents who 
were experimenting with different ways of organising their efforts:
We work in cross functional Scrum teams which include 
product owners, data scientists, data engineers, software 
engineers and scrum masters. Depending on the project this mix 
can vary. Many of these team members will report to different 
people in the organisation but it is important for us to let them 
work as a team. 
One core idea that underpinned a lot of answers was ‘don’t run before 
you can walk’. Before you have an AI strategy you need to know how your 
newsroom works now, something that news organisations have often 
taken for granted in the past:
You need to understand your workflows before automating 
part of them, so it really comes down to knowing yourself and 
what you do before deploying these solutions. When you are given 
an assignment, or come up with an idea, usually the next step is 
to just hand in the content you produced – and what happens in 
between is lost. That process needs to be made explicit when AI is 
involved, and that implies understanding that not all of your 
work as a journalist has to do with creativity. 
2.2 Ready for AI?
These are still relatively new, diverse and complex technologies, coming in 
the wake of a series of other digital challenges. So it is not surprising that 
respondents are deeply divided on AI-readiness. They split approximately 
in half between those who felt they were catching the wave and others 
who hadn’t done more than dip their toes in the water. There was a vein of 
optimism, especially as many of our respondents were early-adopters who 
feel they have already made the first steps::
We are aware of developments, we have units that deal with the 
topic, we have projects that tackle the issues. 
42 41Many respondents had become aware by embarking on AI projects that their 
organisations were not ready to develop a broad strategy – yet. For example, 
there were cultural/managerial challenges specific to AI:
As a large newsroom, we are more familiar with the potential and 
challenges of automation/AI in the newsroom than most. However, 
we still have work to do in spreading this knowledge throughout the 
company so that everyone is aware and thinking about how to 
optimize the technology and also consider the risks. 
These management challenges are frequently mentioned as  
serious obstacles to obtaining uniform or strategic change across  
the whole organisation: 
There is an unbalance between the business areas and  
the newsroom. Cultural change is the biggest challenge,  
as well as having a strategy around AI that goes beyond  
tactical initiatives. 
Among those who claim they are not ready there is a strong sense that 
getting up to speed is an urgent task:
We have too much dependency on third parties and lack of 
internal resources to pretend to be ready. We have to clarify use cases. 
We have to clarify profit and loss for a medium company. We hope to 
be able to have a real AI roadmap in 2-3 years. 
This is a particular problem for smaller newsrooms:
We’ve started, and have ideas, but our organization is  
small and we lack dedicated resources to fully take advantage  
of AI for journalism.  
422.3 How Newsroom Roles are Affected by AI
One of the key areas for any strategic discussion of AI is what will 
happen to jobs. Will the robots take over from humans? Will the 
computer wizkids displace the seasoned hacks? Will traditional skills 
be substituted by algorithms? Our respondents stressed that AI creates 
labour as well as reducing it. But certainly, what people do will change. 
Traditional journalism skills may become more important, but in a new 
setting. Many think AI will affect all areas of the organisation, though not 
in the same ways:
Production, distribution, and consumption of news will all be 
impacted by AI-powered technologies, probably in that order. 
Entirely new content experiences based on AI technologies are 
still the most distant opportunities. In production of news the 
daily routine of assembling audio and video programmes will 
likely be an early area of impact. In distribution and 
consumption of news the personalisation of content offering and, 
especially, the personalisation of the individual content item or 
experience, will likely be an early impact. Both of these are 
happening now in limited form. 
This will mean augmentation rather than replacement. As one 
respondent puts it:
I think the impact will be subtle. I am highly critical of the 
idea of a ‘robot journalist’. It‘s a nice sci-fi imagination, but not 
actually practical or realistic. I think most AI applications will 
become invisible fast and support workflows and reporting, but 
not replace it. Instead we‘re going to see the automation and 
augmentation of tasks, such as translation, transcription, image 
search, augmented writing, automated summaries, maybe some 
form of personalization inside a journalistic framework. I am 
trying to not get carried away by big visions and ideas here. 
44 43One of the core functions of journalism is editing, the exercising  
of journalistic judgement. While that could become more important,  
it will change:
The editors of the front page will need to work in a different 
way. A year ago, they edited a front page the way they edited a 
paper: decide on a unified message, fit the pieces together, and 
make it look a certain way. Today, they understand that different 
users will experience the page differently. That is a different way 
of working. At the same time, the job of an editor is also 
becoming more exciting. Now, they can specify preferences at a 
more granular and dynamic level. For example, “Show this 
article, unless the user has already seen it, in which case show 
this other article”. That wasn’t possible before. If we look out 10 
years though, ‘front pages’ might no longer have a major role to 
play. That will, of course, change how editors work. 
That is fairly typical of how our respondents described emerging change 
and we will discuss what that means for the future in further detail in 
Chapters Three and Four.
As AI starts making an impact, new profiles and small teams are being 
brought into many newsrooms to handle the introduction of AI. But 
overwhelmingly, respondents state that few new AI-specific roles are 
being created within the newsroom, partly for resource reasons. Where 
they are, a key role is to act as ambassadors for the technology: 
While data journalism is a highly promising field, we do not 
employ a team of data journalists, due to a lack of financial 
resources. Within our software departments, we have 
increasingly started to hire data scientists and data engineers as 
well as a team of AI specialists. Apart from big data analyses 
and the implementation of AI-related use cases, their task is to 
give internal talks and trainings to demystify AI and elaborate 
on its actual potential. 
44The majority view is that creating brand new, purely AI-related roles 
might be counter-productive. As the technologies become implemented 
the focus seems to be on adapting existing workflows and roles rather 
than creating completely new ones:
While we have a growing data team that supports the 
buildout of these tools and AI-powered technology, the adoption 
of AI by our newsroom is less about the creation of new roles and 
more about the evolution, training, and education of existing 
resources into more AI and tech savvy ones. We believe that data 
and AI shouldn’t be isolated to a few roles, but that data fluency 
is necessary across the organization. 
This more incremental approach to building AI-literacy throughout 
the organisation is partly motivated by the fact that AI is not the only 
technology or process being developed:
I don‘t think we need an AI-specific role, but someone focussed 
on automation and augmentation of workflows. AI does play a role 
here, but so do dozens of different technologies and techniques. 
Workflows of currently employed journalists are changing, though: 
We don’t have specific roles exactly but a number of people are 
already being affected. Certain production jobs are naturally 
developing in response to this kind of technology. Investigative 
reporters are increasingly au fait with the kind of tasks that 
should be automated. Senior managers are increasingly being 
expected to understand basic concepts and watch out for 
opportunities and new developments. 
Some of those new workflows will mean the creation of AI-focused 
newsroom roles:
We have many AI-specific roles now (currently working in  
a data science team of 8, with data scientists, a data engineer, 
and product owner). 
46 45The overall direction is evolutionary, bringing change through an 
incremental process of adoption and adaption. Nearly half of 
respondents said that they are already AI-active, but about a third spoke 
of timeframes for significant impact of 2 to 5 years. 
BY WHEN DO YOU EXPECT AI TO HAVE AN IMPACT ON  
YOUR ORGANISATION?
44%
19%15%22%   It’s already happening – 44%
   By next year – 19%
   Within the next 2 years – 15%
   In 3 to 5 years – 22%
In most newsrooms there was uncertainty about how that impact will 
be realised. Ad hoc or flexible strategy may be a practical reality but it 
means that systematic planning is hard. As we shall see in Chapter Four, 
there is a wider debate about the real potential of AI in other industries 
and that is reflected in the responses from our newsrooms. At one 
extreme there is scepticism of any serious effect: 
I don’t think it will ever have significant impact. 
At the other end the feeling among a few was more fundamentalist:
This is happening: however, this is not a technological shift 
but a cultural paradigm shift. 
This reflects the way that AI technologies could reinforce inequalities 
between news organisations of different sizes and with different 
resources. Change is coming but it will be unevenly distributed.NB: Responses were aggregated in 
bands by the research team.
462.4 The Strategic Challenges to AI Adoption
The biggest challenges to adopting AI cited by our respondents were 
resources and knowledge or skills. But as significant as either of those 
was cultural resistance: the fear of losing jobs, of changing work habits, 
and a general hostility to new technology. Lack of knowledge about AI 
across the news organisation along with a lack of strategic managerial 
insight were important too. But perhaps the biggest, concrete factor 
was the lack of specialist staff who know about the technology and 
how it can relate to the newsroom. Other issues were also significant 
such as the quality or relevance of much of the technology on offer and 
concerns around ethics such as filter bubbles, accountability, and legal 
issues [We deal with those in more detail in Chapter Three] . 
THE MAIN CHALLENGES TO AI ADOPTION ENCOUNTERED BY  
OUR RESPONDENTS:
1 	Lack	of	financial	resources	and/or	willingness	to	invest	the 	available	ones.
2 	Lack	of	AI-related	skills	along	with	the 	difficulty	to	attract	and	hire 	talent.
3  Skepticism towards new technologies, combined with the fear  
of job losses.
4  Structural issues, including technical gaps between departments.
5  Lack of knowledge and understanding about the potential of AI.
6  Lack of strategy, especially at the management level.
7  Lack	of	time	and	difficulty	to	prioritise 	AI	projects.
[Other challenges include: data quality, ethical concerns, complexity, 
inadequate tech infrastructure, language-related barriers, low accuracy 
of existing AI tech.]
Encouragingly, the challenges were not always seen as insurmountable.  It 
is not surprising that there is a knowledge gap with such a relatively new 
and complex set of technologies, but it has wider significance than just an 
information shortfall. It is seen by respondents as a barrier to progress:
48 47There is no common understanding of the term ‘AI’ and when 
implementing ML [Machine Learning] algorithms can actually 
be helpful. This does not only lead to false expectations but also 
turns the search for proper use cases into a challenging task. 
Related to this is a wider cultural resistance, coloured by fears of  
‘tech hype’:
I think one of the biggest problems of AI are the imaginations 
and visions communicated around this term. Most have their roots 
in sci-fi and speculation. We‘ve been trying hard to make this field 
seem as boring as possible to the rest of the company! This helps 
manage expectations and also circumvent any unnecessary 
discussions, because people are afraid of literal job-terminators. 
Journalists are aware that the introduction of new technology has 
sometimes led to more work:
The key challenge is a cultural challenge, as AI does reduce 
processes and thus giving more time to people in the newsroom. 
But that also means an ask of higher productivity, which a lot of 
people may want to avoid. That has been a key issue. 
These cultural barriers may be grounded on valid concerns around 
editorial policy and need to be addressed in a collaborative process of 
internal engagement:
There is a cultural gap between computer scientists and 
journalists. Topics such as algorithmic personalization are 
straightforward and sensible directions for computer scientists, but 
raise concerns with journalists around editorial responsibilities, 
filter bubbles, etc. We need to keep everyone on board, and get 
commitment before developing solutions. The solution is to keep in 
touch/discuss with each other. We (AI team) currently have 
monthly meetings with editors to keep everyone on board, present 
our ideas and request feedback. 
48AI is not a magic solution that translates effortlessly into efficiency and 
innovation. It takes resources. That can create reluctance to engage:
AI is expensive to build and manage. It takes a lot of work to 
ensure data is clean and machine learning is effective. It may be 
the domain of big companies, which can develop and sell AI 
services to smaller companies. 
In the past, as an industry, the news media suffered from a tendency 
to promote journalists into management roles without providing them 
with wider skills or experience. That is changing through the various 
technological and market disruptions of recent years but our respondents 
still report a strong sense that management, who are supposed to 
organise strategy, are not equipped for or even aware of AI issues:
Too little understanding of the technical advantages and 
possibilities – managers don’t know enough about technology. Lack 
of imagination due to poor tech skills. 
AI is complex so it is not surprising that there are management problems:
Among the many challenges we’ve encountered: 
prioritization. How to know what to automate? Which AI project 
comes first? As with all coverage, you have to weigh up the needs 
of the audience, the impact of the reporting, the gains for the 
newsroom and so on. 
But underpinning this is the lack of AI-skilled staff which creates very 
practical as well as cultural issues:
Hiring talented data engineers and scientists is challenging in 
a competitive marketplace where we’re competing head to head with 
banks, hedge funds, and start-ups that can offer more in 
compensation or stock options. 
49 50
AI technologies have their own terminologies and logics and are often 
created for other industries. For some newsrooms it is not seen as 
worth the investment in knowledge and resources. There are issues 
around language and most of all around data quality:
For many AI applications that we want to do, they rely on high 
quality, well-labeled data, but we don’t have that yet. Labelling 
those data needs a significant capital investment. 
Responses indicate that there needs to be a strategic effort in 
newsrooms and across the industry to improve levels of AI literacy and 
to engage with cultural concerns. News organisations need to build a 
skills base to create relevant and efficient products and systems, as well 
as the metrics to measure success or failure: 
The transformation of the whole media industry has 
actually just really begun: no-one has silver bullet on how to 
build and redefine organisational culture that can transform 
its core business and products to thrive in the new emerging 
AI-powered world. The biggest challenge for the whole 
organisation is to understand what is optimisation of the 
current business and its activities and what is needed to 
innovate and build future business. Optimization and 
innovation need different kinds of metrics and KPIs to assess 
what actually works, and what doesn’t. In short: how to coordinate 
resources in the best and most efficient manner to the activities that 
build the future success. 
Some of these are familiar challenges for an industry that has 
become used to grappling with change. But finding the investment for 
addressing the skills and training deficit, for example, is a huge task 
that will need collective action and possibly external support if the news 
media is not to fall behind other industries. 
50
2.5 The Pathway to an AI Strategy
From our survey, it is clear that there is a lack of strategic planning around 
AI. The strategy will always vary according to the nature of the news 
organisation and what adoption stage they have reached, but these are the 
key elements to consider that have emerged from this research:
HOW TO PREPARE AN AI STRATEGY FOR YOUR NEWS ORGANISATION
1 Assess your stage and state of AI readiness 
2  Understand and categorise the kind of AI technologies you are considering 
3  Decide how AI might relate to your brand and general strategy, the problems 
it might solve, or the needs it could meet
4  Evaluate what areas of your organisation might use AI and why
5   Identify key obstacles: resources, skills, culture, management, etc and plan 
how to address them in a systematic way
6  Assign roles and responsibilities and create a communications structure 
across the organisation to include all stakeholders
7  Establish systems of monitoring and reviewing performance and priorities
8  Create a role for external relations with partners, clients, and wider AI 
resources with a mission to investigate and incorporate AI innovation.
It is possible that AI might be deployed in quite narrow areas such as 
the automation of certain functions. But even when deployed in specific 
fields, AI will be most effective when a holistic approach is adopted. 
The experience of our respondents is that isolated efforts will always be 
inherently limited. A strategic approach has to consider the newsroom 
as a whole. AI is innately networked. It requires a skill set, knowledge 
base, defined roles, systematic appraisal, and a culture that relates the 
technologies to editorial or marketing. 
AI will change the way that the newsroom works and its relationship to 
audiences and revenue. As we will see in Chapter Three, that has ethical 
and editorial implications as well as financial or business consequences. 
In Chapter Four we will see how organisations are thinking about these 
future strategies.
51 52
Chapter 3  
Ethics and Editorial Policy
3.0 What Difference Does AI Make?
AI changes the way that journalism is created and consumed but how 
does it change the journalism itself?  What kind of content is produced 
and how does it alter the relationship with the individual consumer and 
society? With any new technology come concerns about its impact on 
practitioners and people in general. Some of the hopes and fears are 
based on false premises and conjecture. We learn from media history 
that ‘new media’ such as printing, radio, or TV also raised utopian hopes 
as well as dystopian moral panics.49 Technology should not be seen in 
isolation, but it does have effects that go beyond practical issues. AI 
raises concerns because of its power and its potential to influence all 
aspects of journalism and especially because it can seem a complex 
and hidden technology.
Our respondents were generally tech-savvy so were overall less 
worried about the negative impacts of AI than other parts of the news 
organisation or other stakeholders might be. But that familiarity means 
that they do have insights into the effects of AI on journalism. There 
were six key areas of debate they raised, which are all inter-related:
• Economics: savings or investment?
• Algorithmic bias
• Misinformation	and	‘filter	bubbles’
• Enhancement of editorial decisions and transparency
• Balancing	artificial	and	human	intelligence
• The role of the technology companies
52This chapter looks at what newsrooms thought about 
the ethical and editorial issues around using AI. This is 
what newsrooms are telling us, not a detailed guide to the 
technology or to solutions. By ‘ethics’ we took a wide definition: 
thinking and practice related to issues such as trust, accuracy, 
accountability, and bias. By ‘editorial policy’ we mean a broad 
range of issues around the idea of the ‘quality’ of news.50 
How does AI change the standards or nature of the content, and 
the social value of its relationship with audiences? Journalism 
itself has a chequered ethical history and levels of public confidence are 
not particularly high at a time of unprecedented political and economic 
pressures.51 At the same time there has been a public debate about 
AI in general: do the algorithms discriminate against certain groups of 
people?52 Will this technology lead to mass unemployment?53,54 How does 
society hold this technology accountable?55
Newsrooms told us how AI was impacting on their relationship both 
to content and to the public. We also asked about their attitudes to 
responsibility or control over the technology and its effects, especially 
about the technology companies that provide specific tools and general 
infrastructure. These were not just philosophical concerns, although 
they do get to the heart of the idea and purpose of journalism [See also 
Chapter Four] . They are also practical, immediate questions. In a world 
of increasing misinformation, for example, trust is key to securing the 
confidence and attention of users who might then support a newsroom.
About one fifth of respondents stated that they are not particularly 
concerned, at least at the moment:
I am more excited than concerned regarding the impact of AI. 
As opposed to the current negative sentiment towards AI, these 
technologies will augment the newsrooms and save valuable 
resources to be directed toward serious issues that require the 
attention of journalists. 
53 54
It might be that in certain areas of journalism work there is a legitimate 
trade-off between an element of quality lost and another value created. 
Journalism has often been about making compromises:
Especially in the early days of robot journalism, we’re trading 
quality for quantity with the bet that as a whole it still provides a 
more relevant user experience. I personally think this is the right 
thing to do. It is however obviously important to carefully select 
what types of journalistic work this is done for. 
The majority had confidence that overall, the impact would be beneficial 
if news organisations retained their ethical and editorial stance. That 
might reflect the fact that our respondents work for news organisations 
with a good historical reputation for credibility and public service.  Some 
argued that they did not see problems now but they could emerge if AI is 
not properly set up and monitored within the organisation: 
I am not concerned at the moment. I think keeping an eye on 
data bias will be essential, but also heartened that journalists and 
journalism organisations often consider (or at least try to consider) 
bias issues in their work. 
ARE YOU CONCERNED ABOUT THE IMPACT THAT AI MIGHT HAVE  
ON YOUR JOURNALISM?
60%40%   Yes – 60%
   No – 40%
54
3.1 Economics: Savings or Investment?
The most obvious issue was whether AI efficiency savings are ploughed 
back into editorial or used to cushion news organisations against wider 
financial constraints:
The big question is will savings (if any) be reinvested or used to 
counter generally declining incomes? 
A minority were concerned that where AI is used for efficiency it could 
diminish the value placed on human input:
There is potential for higher rates of ‘low value’ journalism to be 
churned out quickly. The role of reputable news organisations to 
analyse and verify stories may become a scarce resource. 
Most respondents were confident that savings would be used to invest 
in the development of the technology or to enable better journalism. 
However, there were broader fears that AI might accentuate inequalities 
between news organisations, with implications for media diversity and the 
sustainability of ‘quality’ journalism production:
The biggest concern around quality of work is how non AI-
enabled work might suffer in comparison to newsrooms that have the 
resources to build/buy and deploy AI effectively. In other words, there 
may well be an arms race that only the most well-resourced 
newsrooms can compete in.  
News organisations recognise that they face an ethical choice. If they take 
short-term financial decisions they risk undermining their value to the public 
as well as journalistic standards. Clearly this depends on their corporate 
mission and how they define ‘quality’:
Automatically generating articles from erroneous databases can 
lead to the spreading of false information, potentially under the label 
of a media brand that is considered trustworthy by the public. In 
general, it is essential to keep in mind that the objective of a high-
quality newspaper cannot merely be economic success. If a machine 
learning algorithm is trained to maximize revenue, the risk of 
valuing click-bait articles more than investigative research projects is 
high. Therefore, it should be carefully considered what metrics to 
optimize for and how to maintain the quality standards.  BY WHEN DO YOU EXPECT AI TO HAVE AN IMPACT ON  
YOUR ORGANISATION?
44%
19%15%22%   It’s already happening – 44%
   By next year – 19%
   Within the next 2 years – 15%
   In 3 to 5 years – 22%
NB: Responses were aggregated in bands by the research team.
55 56
Many respondents were confident that positive choices were being made:
I have a decent chunk of faith in established media 
organisations, working in one myself. Any new technology, no 
matter how automated and computerized, always lends itself to 
misuse and I am certain there are and will be those who take 
advantage of that. Still, truth is a commodity that never loses its 
value and most journalists, I’m sure, realize this and will use AI 
to empower truth to the best of their abilities.  
3.2 Algorithmic Bias 
All algorithms can have some kind of ‘bias’,56 just as all journalism has 
some degree of ‘bias’ that reflects its production. Broadly it can be divided 
into a ‘production bias’ that is inherent to the data inputted, the training of 
the data and its operation. These might be quite technical factors, such 
as data classification categories, but they might still be significant in 
determining the quality of the content and how it is consumed. 
Then there are biases that are perceived as ‘unfair’ such as racial or 
gender biases. This kind of bias is not only socially unacceptable, but it 
also runs the risk of moral, political, and even legal hazard. All systems 
will be biased in the sense that they will reflect the intentions and 
assumptions of the people who create and use them. What matters 
is how aware you are of the bias and how you manage and minimise 
it.57  This means that the ethical and editorial issues will depend on 
systematic strategy . The overall feeling was optimistic, but around half 
of respondents did raise concerns about AI applications:
I am concerned about journalists’ complacency and over 
reliance on algorithms and how they may end up doing a 
disservice to our audience. There are currently many cases of 
bias in journalism that comes with use of AI. Poorly trained 
algorithms may do more harm to journalism.  
56
The ability to monitor and correct algorithmic bias requires a high degree 
of knowledge.58 It demands technological expertise and the time and 
resources to apply it within the constraints of a newsroom. Journalists 
have the additional responsibility of explaining it to their consumers:
Journalism needs to lead the way in transparency around 
how algorithms and data are used. If an algorithm is employed, 
we should try to demystify it, help users understand it and where 
possible control how it affects them.  
3.3 Misinformation and ‘Filter Bubbles’
One concern was around the credibility of journalism, its role in 
countering misinformation and in promoting healthy public debate. In 
the battle against misinformation journalists need to have control of and 
confidence in their tools:
Errors in the application of AI can put credibility at risk in 
times of political attacks and fake news.  
Others pointed out the wider ethical challenges of AI technologies 
and information. For example, its increasing role in promoting (and 
countering) misinformation generally:
Machine learning is perfect tool for generating deep fakes 
and fake content, and it will be a major problem for all news 
outlets and credible media. Also content verification will become 
much more difficult and/or tool-dependent. We need ML tools to 
spot ML fakes. 
Many respondents highlighted the danger that algorithmic 
personalisation could further entrench what cognitive psychologists 
call ‘confirmation bias’, the human tendency according to which people 
prefer to be served up content that reflects rather than challenges their 
own beliefs and values.
57 58
This is a complex and often subjective issue. Recent academic research 
has shown that people who consume news online might actually get 
a more diverse range of content,59 especially compared to traditional 
media habits which may have been even more aligned along partisan 
lines.60 But regardless of the absolute or overall trends, respondents 
were concerned that commercial imperatives should not accentuate the 
problem of so-called ‘filter bubbles’, polarisation, and conflict:
The filter bubbles in social media today are highly dangerous 
but we hope that these will be addressed over time, by changes to 
algorithms, better rules and standards on transparency and by 
audiences who are more familiar with these effects. 
Many respondents are already addressing these issues by shaping the AI to 
fit their ethical or editorial policies:
Our systems are placing a higher value in the ranking of 
sources on certain key quality indicators such as originality (does 
this source specialise in this topic?), diversity (is this source 
providing a unique point of view or reflect an underrepresented 
voice?), truth (does this source have a record of misinformation?). 
There are other criteria possible for such de-biased work on AI 
including emotion and readability.  
For our respondents this was a good case for the idea of ‘augmented’ 
journalism: combining human editorial insights with AI:
Something that we do to prevent pushing users into a certain 
ideological direction is to factor in an ‘editorial score’, which is driven 
by human judgement about the importance of a topic to scale up the 
curation service that our newsroom provides.  
But dealing with AI is not always straightforward and may mean that certain 
applications should simply not be used:
In our experience using AI to measure, say, the fraction of sources 
who are male/female is very unreliable; it’s hard to automate the 
assessment of gender, particularly with foreign names. So if we are 
going to do things like that, it’s safer not to use AI at the moment.  
58
We are trying to get rid of biases in training data, but if we can’t, 
we should identify them and inform users. If we can’t identify biases 
(or biases are hard to characterize) within a dataset, then that dataset 
(and that AI algorithm) should not be used for editorial purposes.  
How news organisations deal with algorithmic bias and the way that 
personalisation might shape public opinion will depend on their own 
ideological leanings and policies. But the first step is having the knowledge 
and information to understand how the AI creates bias in the first place:
Bias is inherent in all storytelling. AI is only as good as its 
inputs and, as it’s made by humans, may have bias due to the 
creator’s bias. 
3.4 Can AI Enhance Editorial Decisions and 
Transparency?
All newsrooms have ‘biases’. Some can be ‘positive’ such as a particular 
focus on certain issues. However, recently there has been a debate 
about whether traditional journalism culture creates a lack of diversity 
in editorial agendas and whether newsrooms are out of touch with 
sections of the public or certain areas of public concern. Could AI help 
uncover issues, stories or facts that would otherwise have been missed? 
Could AI assist in creating journalism that is less limited by professional 
assumptions or norms? 
A majority of respondents said that they had not experienced this 
corrective effect yet. Their focus is still very much on the bias of 
algorithms or the audience rather than journalistic ‘filter bubbles’. But a 
substantial minority said that questioning AI bias in itself had led them to 
reconsider their assumptions and to think again about what readers want:
I think AI has a role to play in helping expose the biases and 
unintended consequences that already exist within the industry 
too. It is an opportunity to reflect on how we make decisions, to 
‘rearchitect’ it in fairer ways. 
59 60
One way that AI helps challenging newsroom assumptions is through 
audience data:
The tools we have used (headline testing, propensity models, and 
recommendation) show us that what we think might interest readers is 
not always aligned with what really interests them. There is a strong 
bias towards what we consider ‘serious journalism’ that is not 
necessarily what our audience requests. 
Audience feedback can help optimise content provision even when that goes 
against newsroom instincts:
Newsrooms tend to find new stuff so much more relevant that 
sometimes it’s hard to provide necessary context from older stories. It’s 
something that our personalization algorithms are better at. 
I think it’s a cycle where we improve one another. AI made us 
realize our bias and vice versa. In newsrooms, editors tend to make 
decisions based on gut feeling and experience, and not data. AI made 
us realize that we have to change that bad habit. 
As we will discuss further in Chapter Four, underlying this is the potential for 
AI to make journalists reconsider the fundamentals of the industry: What is 
information? How do journalists decide what is true or important? What does 
the public use news for? AI has the power to gather, arrange and interpret 
data from a wider range of sources but how far can it reform traditional 
formulae and replicated practice?
AI makes you question everything. AI models are only as good as 
the humans who structure and train them. It normally reflects the 
knowledge and understanding of journalists about certain topics. We 
are very careful to apply the same standards that we have in our news 
gathering to the AI tools we develop. It’s also necessary to constantly 
re-train the AI and test for biases, which is also part of our process. 
This trend towards greater awareness of processes led our respondents 
to cite greater transparency as a way of avoiding the damage of the issues 
such as algorithmic bias and to build public confidence:
It always depends on how a news organization decides to handle 
it: Transparency is the key here. Users should never be kept in the dark 
about how content was generated and distributed. 
60
Newsrooms have become much better at showing their workings, partly 
in response to a perceived crisis of trust in the news media61 and the 
need to distinguish between authoritative, credible, verified journalism 
from misinformation online.62 AI can help because it can show who 
consumes what content:
Knowing which users get exposed to which content, and to a 
certain extent being able to factcheck the choices made by 
technology on journalists’ behalf. 
But this will be hard because as they become a routine part of 
journalism work “most AI applications will become invisible fast”:
There is a need to start thinking about transparency in the 
distribution of our work to gain public trust. Algorithms should 
not mirror past or ongoing bias of its user, both at individual and 
institutional level. We must think deeply about embedded bias and 
the impact thereof. 
To address that means paying more attention to what newsrooms 
mean by standards and how quality is demonstrated:
If we design and use the AI-based systems in a meaningful 
way, I don’t see any reason to worry about quality or creativity. But 
for that we have to clarify what journalistic quality means. Where 
do we need two primary sources, where is one sufficient? On the 
ethical side, I consider the question of communication and 
transparency to be crucial. In order not to gamble away the trust 
our readers have in us, we have to communicate effectively which 
contents of algorithms have been created and according to which 
principles this has been done. 
One key area will be around the privacy of data used by AI, including 
around new platforms:
In the arena of AI Assistants, the concerns currently raised  
by social platforms around issues like privacy, choice, echo 
chambers, and so on, may very well be amplified and this is  
a very present concern. 
61
Newsrooms are thinking about how to formalise their oversight. There 
will always be bias, but what about accountability?:
In theory, smart skepticism and an open mind should drive 
newsrooms to constantly question their assumptions, data, and 
biases – but it’s hard to do in practice and harder to do when it’s 
codified in, well, code. There may well be a need for some kind of 
newsroom watchdog, internally or externally, to regularly 
question bias. 
Transparency as an aspiration is noble but unless it is part of the 
work system and unless the standards are public, it is not effective. 
The Associated Press , for example, is reflecting on how to expand its 
stylebook to reflect these concerns, but there are a raft of possible ways 
of addressing it such as proper source attribution in the content itself.63
There are codes that attempt to grapple with the 
particular issues raised by digital technologies and 
journalism such as the ONA social media code.64 
There is now a need for new codes or guidelines 
for AI. One critical element of creating that kind of 
effective transparency would be, as Paul Bradshaw 
has argued, for journalists to be more clear about 
the limits of AI and the degree of uncertainty.65 This 
kind of transparency work could draw upon other 
disciplines such as finance and medicine.66 But there 
are already practical ways that newsrooms can be more transparent 
such as citing AI in an article byline.67 This is not a problem journalists 
can solve by themselves when so much of their work is dependent on 
the infrastructure provided by tech companies:
News media doesn’t really have the last say on editorial 
guidelines and editorial work. The current tech platforms and 
their algorithms become the all-encompassing editorial filter, 
which the news organisation can’t really directly affect. 
As we shall see in section 3.6, this is part of wider concerns about the 
relationship with the tech companies. 
62
3.5 Balancing Artificial and Human Intelligence
One of the key ethical and editorial concerns was losing the ‘human’ element 
of journalism:
Automation could lead to less ‘human intelligence’ in reporting 
which may have unforeseen consequences. 
The concern included a variety of issues. We have already dealt with the 
cultural hostility towards technology and the fear of losing jobs within 
newsrooms. But there were a range of other fears around journalism 
becoming more algorithmic. One was the devaluing of newswork leading to 
diminution of the status of journalism:
Does journalism become less attractive to the ‘master 
storytellers’ if and when content is co-created or even repackaged  
by AI? Does the automation of basic tasks lead to a decline of 
journalism fundamentals? 
When considering the ethics and editorial policy related to AI there is more of 
a need for journalists to monitor the machines:
With the agreement of our audience, we could try to personalize 
everyone’s newsfeed based on similar behaviour, improve the 
completeness of our content metadata, recognize automatically faces, 
names and useful data in our stories, and so more. But we see the 
necessity to keep a strong human basis for each meaningful decision 
we make on a daily basis. 
It is a balancing act, but respondents were clear that the ‘human values’ 
of journalism must be imbedded in the adoption of the technologies 
from the onset:
To make sure that the impact is a net positive, the  
journalistic values and principles need to govern the 
development of AI solutions. 
‘Human values’ according to our respondents apply to audiences and 
journalism’s social role: 
63 64
If media outlets are too much driven by wrong technical metrics, 
they can encourage journalists to try to compete with robots or game 
the AI recommendation systems. Instead, patience, perseverance and 
curiosity are valuable human qualities and should be encouraged 
inside the newsroom. 
In a world where so much information flows through networks, the use 
of AI in journalism raises ethical questions for society as a whole, not 
just for the news industry:
The biggest mistake I‘ve seen in the past is treating the 
integration of tech into a social setting as a simple IT-question. 
In reality it‘s a complex social process. 
3.6 The Role of the Technology Companies
[Declaration of interest: this research is supported by the Google News Initiative.]
Technology companies all have different business models and company 
cultures and so their relationship to journalism as well as to AI varies 
greatly. Tech giants such as Google, Amazon, Apple, Facebook, and 
Microsoft all do research, create products and provide infrastructure 
used by news organisations. Some also fund journalism production and 
support newsrooms or journalism education and innovation. 
Publishers argue that these companies compete with news 
organisations for advertising revenue and for people’s attention and 
time. They provide the devices and networks where much journalism is 
distributed and many of the tools vital to journalism production. Their 
appetite for data is massive and their spending on AI technologies is 
huge. So inevitably the relationship between news organisations and the 
tech companies described by our respondents is ambivalent: 
They provide us with valuable tools, but media companies 
should always question the [tech companies’] motives. Content  
is still king and most of their products remain virtual without 
our products. 
64
It is a constantly changing relationship. Shortly after our survey was 
completed, for example, Facebook announced its News Tab feature that 
will use a combination of journalists and personalisation algorithms to 
curate a separate news feed of content from publishers, some of which 
it will pay for.68 Google has just announced that it will alter its algorithms 
to promote ‘original’ journalism content in its search results.69
Our respondents were generally well-informed about technology and 
positive about its role. But a few did express overtly hostile sentiments 
about the tech companies:
Facebook, Google are AI-driven companies impacting the news 
industry by stealing eyeball time and advertising income. 
Our respondents were aware that they do not have complete control 
over the technology. News organisations already work with tech 
companies to create new tools or systems:
Most ready-made solutions come in form of cloud-APIs from big 
tech corporations. This has consequences for the sort of data we can 
upload and disqualifies a lot of those solutions for our work. This 
structure also leads to a form of mild dependence on those 
companies. It‘s harder to switch from one to another, if you‘ve 
implemented those solutions deep inside your own side. The positive 
side is the excellent quality of the models and frameworks. 
The New York Times and El País , for example, use Perspective, an open 
source tool developed by Jigsaw, a technology incubator within Alphabet, 
Google’s parent company, to improve its comment moderation.70 Our 
respondents realise that it might be the tech companies who produce the 
next big thing at the intersection of AI and journalism:
Any future ‘conversational news AI’ will be generated by a big 
tech platform (eg Google), not a news organisation. 
If those tools or systems are to align with journalistic priorities and 
the public interest, then the relationship between the tech companies 
and the news organisations becomes critical. Respondents suggested 
a range of ways that relationship could be improved. It is an unequal 
one because the tech companies have the financial resources and the 
expertise and may have different values or priorities: 
65 66
What drives journalists and journalism – trust, impact, 
furthering understanding, fostering civic engagement and 
dialogue – is hard to measure as a KPI for an industry that is 
driven by hitting metrics. How do we work effectively with tech 
partners when how we think about success is often so different? 
There was a call for the tech companies to engage with news 
organisations in a dialogue about ethics as well as engineering:
I would like to see tech companies that have successfully utilized 
AI, or are indeed developing it, to spread awareness of the many 
uses and act as ambassadors. Technology companies are crucial 
for the successful transition into an AI-powered future. They bear 
a great responsibility in terms of not only getting it right but also 
in terms of creating a healthy ecosystem. 
For that to happen there needs to be mutual critical attention paid by 
both sides to these issues:
An extremely important job for journalists nowadays is to 
follow the steps of big technology companies and to try to analyse 
its algorithms. It’s also important that companies understand the 
importance of this kind of journalism and that they are open to 
talk about it. 
As discussed in Chapter Four, training is vital and the tech companies 
are well-placed to support it: 
Platforms have a vital role to play in training, educating, and 
creating a culture of transparency about AI. For journalists, this is 
critical to the question of trust. 
Many respondents felt under pressure from the hype emanating from 
the technology sector. But they also credit the tech companies – 
however reluctantly in some cases – with leading the way in terms of 
addressing ethical issues in media technology and supporting research:
Some of the big tech companies take leading positions around 
fairness and AI (eg, Microsoft invests a lot in this), and most big 
tech companies do a lot in terms of (academic) publishing and 
sharing, which drives us all forward. 
66
Our respondents said that transparency of the technology companies’ 
AI-related operations was imperative: 
Technology companies make AI technologies more available 
through their cloud services, but at the same time they don’t 
reveal enough insights about how they build up those AI 
machines. They should be more transparent about their 
algorithm and biases in the dataset. 
The platform’s algorithms have a big impact on how news organisations 
can strategise their own marketing. In the wake of changes to search 
and recommendation algorithms in recent years, the most common 
plea was for the tech companies to “be more transparent about changes 
to search and newsfeed algorithms.” This is more than a business issue. 
Recent academic studies have argued that the role of AI technology is 
changing what it means to be transparent. What does it mean to be a 
trusted communicator in the AI age? For the public, the ‘machines’ can 
become the source.71 It sounds theoretical but some have argued that 
this means that the very nature of journalistic authority is challenged by 
this technology if it shifts some of that responsibility to a ‘machine’.72 
That is why some of our respondents want a more shared, open-source 
approach to evaluating the inner workings of the technologies:
Technology companies already propose API to experiment 
with AI at a low cost, and that’s really interesting for every 
innovator in media companies. I’d like to see more open-source 
and offline-first projects that can be manipulated and contributed 
to by us also. 
Respondents argued that a much better grasp of journalism and its 
current problems would be appreciated: 
They have the resources to move the needle: see DeepMind 
and Google. But they also make huge mistakes around data and 
ethics. I’d like them to genuinely embrace some of the problems 
posed in the journalism space and offer us meaningful expertise 
and support to explore some of the questions it poses. I believe all 
the key platforms would also benefit from this: look at the trouble 
they get into whenever they touch journalism recommendation 
and publishing. 
67 68
This is a shared problem. The journalism industry has a poor record on 
open debate about its workings. It has argued that transparency could 
compromise their independence. The technology companies have also 
been slow to adopt transparency. They argue that it is commercially 
sensitive and divulging their codes or algorithms might help bad 
actors.73 But the overall message from our respondents was that much 
more honest dialogue is needed. The agenda around ethics and editorial 
policy (as well as business issues) is large:
Technology companies can and should be part of the 
discussion on how to minimize bias in creating these tools, 
particularly since they employ some of the leading AI researchers 
and build many of the foundational tools and papers in this 
field. We would like to see continued growth in conversations 
and funding from the likes of the Google News Initiative and the 
Facebook Journalism Project. Ultimately, these conversations need 
to lead towards better policy and protocols. 
3.7 How Should Journalists Debate AI Ethics?
The debate about ethics and editorial policy and AI needs to be 
embedded in product development, not just addressing the outcomes.74 
Journalists need to be technologically competent enough not to leave 
that discussion to developers or technologists. And that debate must 
always include the user perspective.
The ethics/editorial debate also needs to consider the wider social 
impact – including the benefits of AI. That is something that is starting 
to happen. The Knight Foundation ‘AI and the News Open Challenge’, for 
example, has seeded a range of initiatives to identify and address these 
issues.75 The responses to this report suggest that it is a debate that is 
welcomed by newsrooms.
68
4.0 Where is This All Going?
We asked our respondents to think ahead. If you had the resources 
what would you do next? What aspects of AI would be most useful for 
your organisation in the future?  We also wanted to know what might 
help that happen. Finally, we asked them to consider how the industry as 
a whole might be changed and how the nature of journalism itself could 
be transformed. The news organisations we surveyed are all at different 
stages of AI adoption, so for some people the future is already here, 
while for others it is still science fiction. 
There were three levels of future thinking:
•  First level:  To improve and iterate what is happening now with 
existing product and editorial teams
•  Second level:  Medium-term innovation over the next 2-5 years 
with newer applications
•  Third level:  Innovation and experimentation for the long-term that 
might include completely new approaches or structures. 
Our respondents were generally involved in technology and editorial,  
so other parts of the organisation might have different visions of what  
is to come. 
The future development of AI in general is not a smooth upward curving 
graph. There are still fundamental debates within the AI world about the 
best pathways forward. Much long-term AI research is currently based 
on the idea of deep learning but some computer scientists argue this 
might be an ‘evolutionary dead end’.76 That kind of debate goes beyond 
the scope of this report but more immediate concerns were raised.77 
70 69Chapter 4  
The Future of AI  
and JournalismWhat surprised us was that when we asked what would help them  
meet the challenges of an AI future, the two key concerns cited by  
our respondents had not directly to do with the technology itself.  
46 per cent mentioned training, education, and literacy in the newsroom,  
and 43 per cent cited the need for recruiting people with new skills.
Another strong non-tech theme for the future that emerged from our 
survey was the potential for collaboration between newsrooms and with 
other organisations, such as universities, and the need to learn from 
other sectors and how they use AI. Our newsroom respondents insist 
that journalism can thrive in an AI world, but there is a real fear of being 
left behind in the wake of technological advances.
4.1 Future Applications and Strategy
The three most common areas for our respondents’ future AI-tool 
wishlist were for:
•  More automatic tagging/entity extraction (newsgathering)
•  Better machine-generated content (news production)
•  Better personalisation/recommendation engines  
(news distribution)
There was a strong interest in AI that can help with the relationships 
between the newsroom and content, or newsrooms and audiences, in 
more nuanced ways:
I believe the most radical change in our case as a 
broadcasting company isn’t AI integration within newsroom 
processes but a layer of AI between our content and audience. It 
would be exciting to understand voice request from our audience 
and to be able to articulate answers based on our archive content 
AND not to be dependent on third parties and their frameworks 
(Google, Amazon, etc) between us and our audience. But of 
course that’s not doable at this time. 
70
Those kinds of new AI-assisted relationships would often 
require structural changes in other newsroom technology to 
properly integrate and facilitate AI, turning a level one innovation 
into a medium or even long-term newsroom development:
We would rebuild the IT systems from scratch  
and a generation change at key positions in the  
newsroom management. 
This kind of grander ambition may simply be beyond  
individual newsrooms:
I would build a system that can ingest gigabytes of text and 
answer questions about current affairs, in a conversational 
format. No news organisation has the resources to do it, and the 
corpus of available articles from any one publisher is too small to 
be used to train a big deep-learning system in any case. 
Some respondents were weary of the pace of change and reluctant to 
think big about the future:
We will focus first on understanding what we have  
already done. 
But most had ideas for newsroom structural change to build, manage 
and develop AI.
As we saw in Chapter Two, strategy is understood to be critical but 
evolving. While there were cultural and knowledge barriers to developing 
AI, staffing was seen as the key resource issue for the future. More 
resources to develop particular tools or products will not be sustainable 
without a different, AI-cognisant organisational structure:
Having the ability to experiment much more on technologies, 
products and formats would be great, but integrating those 
innovations into the existing organization would be difficult 
without (probably) some significant organizational change. 
71 72
The first step to this future would be to understand how to get there:
I would invest resources into explaining where we need to go as 
legacy media company and devise a strategy where employees and 
departments are able to pave the road as we go. It’s not possible to 
make detailed plans with the current speed of tech development. 
Without understanding the potential and the limits it’s impossible 
to devise a strategy and be competitive in the future. 
The majority of our respondents suggested creating teams to develop 
an integrated AI and data strategy, and then prioritise and enforce it 
with adequate funding. Perhaps this is not surprising as some of our 
respondents work already in teams like this. But while these would be 
distinct units, often working on specific projects, most respondents 
stressed the need to integrate with the wider newsroom. The respondents 
suggested two approaches, experimental and multi-disciplinary: 
i. Experimental:
I would build a small team tasked with experimenting with AI. 
Any project would need a relevant editor or journalist attached. 
They would be asked not to build final products but to start 
identifying promising routes and possible dangers. 
I’d set up an internal lab with a core team of AI experts that 
colleagues from every department could join for one or two months 
to analyze their processes, to do research on our readers’ 
understanding of AI-driven content, to test new tools or to invent 
them themselves. 
ii. Multi-disciplinary:
I think we would need a small team focussed on a broader 
aspect, such as automation and augmentation. The team should 
also be comprised not only of journalists and developers, but also 
social scientists and designers. The team should also not be 
anchored inside the newsroom, but instead be a bridge to different 
parts of the company, so resources and knowledge aren‘t used 
inside a silo alone. There‘s a lot more to a newspaper than the 
newsroom alone. 
72
I would create a side team with approx 15-20 journalists (text, 
video) + a dedicated project team (PO + UX + UI designer + 
graphic designer + motion designer + 3 devs and 1 tech lead + 1-2 
developers) + 2 PMs + 4 data analysts + 1 growth analyst and one 
Project Director. This team would play on a dedicated support and 
on 5 per cent of our audience (volunteers of course). It would have 
it roadmap and defined prios/KPIs. But it would be a very nice 
place to work :-). 
4.2 The Need for Education and Training 
The biggest future wish from respondents was for general education 
and specific training for AI. Literacy was seen as vital throughout the 
news organisation to change culture and improve understanding of new 
tools and systems. Explaining and demystifying AI was seen as a way to 
get others to use it:
Literacy is crucial. We are looking at how to better educate our 
journalists on everything from rudimentary coding through to 
data science. The more that the newsroom at large embraces the 
technology and generates the ideas and expertise for AI projects, 
the better the outcome, in our experience. 
This training could be done via online courses or by third-parties but it 
would be as much about the development of the newsroom as a whole, 
as individual learning:
Basic training around how this technology works and  
around what potential applications are might lead to people 
identifying applications that we have missed, hence enabling  
the discovery of opportunities. 
Skills training could be for specific functions but might also include 
basic, foundational knowledge for journalism such as coding:
We all need specific AI training: even the ones working closely 
on the initiatives don’t fully understand the technology and, 
therefore, can’t envision the possibilities. The new competences 
would be, for the newsroom, AI literacy and data analytics; for the 
technology teams, low level knowledge of the AI solutions. 
73 74
Lurking behind this need for AI training is the shortage of editorial 
staff with STEM (Science, Technology, Engineering, and Mathematics) 
subject literacy and the ability to reflect on how that relates to their 
existing journalism practice and principles:
All journalists don’t need to suddenly know how to write code, 
but they should want an understanding of the basic tools needed 
to navigate the brave new world. That means building core 
competencies around math, data and computer science. With 
some automation projects, you are often trying to codify news 
experience and judgement. That requires journalists to think in 
a structured way about why they make certain types of decisions, 
so the machine can learn. 
Some respondents suggested that innovation training should include  
an experimental element rather than simply handing down templates  
for action:
I think that training should focus on experiment ideas with 
small teams composed of people from different fields. It would help 
communicate each others ideas that could have a great impact in 
the future. 
AI training was seen as required for all involved as part of  
career development:
Those who have no prior training in computational 
journalism need to have basic training. That also includes basic 
training on data scraping techniques. Those with more 
understanding need more training on ways to apply deep 
learning or machine learning on real life stories. 
Understanding AI was seen as vital knowledge for 
management throughout the news organisation. 
Not just to improve their systems but to foster 
learning from other places about how the 
newsroom needs to adapt strategically:
74
Awareness-raising: what is the state of the art among 
competitors, understanding what is actually happening in 
newsrooms elsewhere, and then identifying how this tech might 
change different roles in our newsroom – and just capturing 
that. Identifying how it might augment our performance and 
output and not replace us. Looking at similar/other industries 
that we think are doing it well. 
As we saw in Chapter Three, the broad issue of ethics needs to be 
understood to help tackle AI bias and other ethical concerns. Only with 
better insight can transparency operate in a systematic way: 
A basic understanding of the inputs and variables 
that feed the algorithms to minimize bias. Established 
feedback and iteration process. Open and transparent 
discussion on filter bubbles, ethics, and Q&A on AI 
initiatives in editorial town halls or other forums. 
Establish a test group across multiple desks with various 
editorial functions (eg, subs/reporters) to demo new 
features and provide feedback. 
Beyond training, newsrooms need systems for continuous 
information-gathering about trends in technological change:
Newsrooms and journalists need more discussion and 
training around where technology is heading, how it might 
change the world they live in, and what role news might play in 
it. That’s less about learning specific technology or AI skills, and 
more about understanding the pace of change, what’s possible, 
and how to stay current. 
Not everyone in a newsroom needs to know everything about AI. But at 
least some people need to have a much more sophisticated overview of 
the overall, systematic impact that these technologies can have:
75 76
I think anyone who uses AI in a newsroom needs to know a few 
things: at a relatively high level, how an AI system works. eg, 
define a problem, collect data, build a model, evaluate the model, 
productionise, feedback into the problem definition, iterate. I think 
there is a misconception that building the model or tool is the hard 
part, when in fact the complexity lies in the definition and 
evaluation phases. I think it’s also important to understand 
exactly what the system is doing, before you can make editorial 
judgement. What are its constraints, what are its limitations? 
Then there are specific things that a more involved person might 
need to know, eg, evaluation metrics. 
A minority felt that more high level training or education should not be 
wasted on the newsroom. They saw it as the job of the tech people to 
create tools that don’t require special knowledge:
It is for technologists to create products and services which are 
easy for journalists to use, and they should only be introduced to 
journalists when they are intuitive and user-friendly. Training on 
them is then no different to training on other pieces of technology. 
AI needs to be demystified. 
If we do our job right, AI will become invisible in the daily 
work. The only exceptions might be our data teams, but they‘re 
already on it. 
4.3 Newsroom Collaboration
For an industry that has traditionally competed rather than cooperated, 
the enthusiasm from our respondents for collaboration around AI 
represents a significant shift in thinking and even in the way that news 
will be produced. Our respondents tended to come from varied career 
backgrounds so might have more experience of collaboration than others 
in the newsroom, but it is a real trend in the news industry.78 Technology 
drives this but it is also a response to market and audience changes and 
even ethics. All but a couple of respondents agree: more collaboration 
is needed. Collaboration within newsrooms was a theme in the earlier 
sections but it is also a precondition of collaborating externally:
76
A major barrier to innovation with AI technologies is the 
insufficient understanding that news organisations have of their 
own internal processes and workflows. It’s hard to know how to 
automate a process that is only vaguely understood by the 
organisation that’s doing it. Clarifying those processes/workflows 
would be a good starting point for collaboration. 
AI offers opportunities for working with other organisations. This 
could be across a wide range of activities including R&D, investigative 
journalism, data sharing, and training. Collaboration could include 
working on certain problems together with other news media:
Newsrooms across the country would benefit from a centralized 
database of historical articles for AI and ML purpose. 
Collaboration could also involve technology companies, academia, and 
civil society organisations. A few respondents felt that either they were 
already doing enough practical collaboration or that it was too early, but 
generally there was an openness to working together:
More collaboration would be good amongst media 
organisations, but also with other disciplines like social scientists 
to help operationalise data. Also a united approach to ethics in 
data and AI. 
Collaboration can be economically efficient. Working collectively would 
help fund research for example:
More collaboration would be useful, because individual 
publishers may be unable to invest sufficiently in the innovation 
and product development necessary to exploit AI technologies for 
news. Pooled innovation teams, with clear strategic goals that 
align with each collaborating organisation, might enable more 
impactful R&D. 
The news media is incredibly competitive at the moment and is rightly 
proud of its independence. It is often the smaller organisations that are 
most open to collaboration but the idea of intermediaries to facilitate 
was suggested:
77 78
It can be difficult for competing newsrooms, often with a strong 
culture of independence, to work closely together. Ironically, it’s the 
smallest newsrooms that can often put that aside more easily. What 
may be needed are honest brokers – in academia, non-profits or 
funders – who can get people around a table and work out terms of 
engagement that everyone can agree to. 
Collaboration has benefits but it also has costs:
We believe collaboration is absolutely vital to the success of AI 
in this field. However, collaboration is a job in itself. Organising 
across geographies and organisations is very resource intensive. 
But if we want to build globally applicable tools you have to make 
that trade off. 
In a world where news is often transnational, collaboration can make 
sense for coverage of global issues:
Cross-border newsroom collaboration is a hot topic in journalism. 
We see examples and would like to see more in case of bigger global 
topics (eg, cross-border corruption, climate change). 
It can also have value within individual countries, with respondents from 
the Czech Republic, the Netherlands, and Scandinavian countries all 
citing examples of cooperation that could become models for the future:
The Danish equivalent of the Associated Press is trying to 
establish a collaboration on NLP, analyzing and tagging of content 
between Danish media companies. Hopefully just the beginning. 
At least in Scandinavia, the guards are down when it comes to 
sharing progress and findings on the topic of AI technologies. This 
is due to the fact that everyone sees the real competition moving 
from competing newsrooms to the big influential tech platforms. 
78
One organisation set up specifically to collaborate is The International 
Consortium of Investigative Journalists (ICIJ)  that not only helped deliver 
some outstanding multinational journalism with the Panama Papers,79 
but also acts as a resource for training and collaboration more generally. 
It has collaborated with the Quartz AI Studio, Stanford University, and 
numerous news organisations. It is a good example of an intermediate 
body funded independently able to provide resources and expertise on 
AI-related journalism.
4.4 Collaboration with Universities
Universities that teach and research AI are increasingly partnering with 
news organisations. 
This falls into three broad areas: collaboration on specific projects; 
support for research and development; and training/recruitment. 
The Washington Post  has set up a computational political journalism 
R&D lab in collaboration with Professor Nick Diakopoulos, director 
of Northwestern University’s Computational Journalism Lab. The 
partnership has a relatively narrow focus: “to experiment with 
algorithmic and computational journalism tools to support The Post’s 
political data efforts in advance of the 2020 election”. But it is a model 
for how newsrooms and universities can find ways to work together for 
mutual benefit.80
Universities have access to research funding and specialist researchers 
with broad and deep understanding of AI, often working at the cutting 
edge of this emerging technology. They have long-term timeframes. While 
they have budget constraints they are not under the same commercial 
pressures as news organisations. They are also keen to develop 
links with practitioners to share expertise, test ideas and prototypes 
and to demonstrate relevance to the ‘real-world’. They can connect 
news organisations to other partners such as technology companies. 
Collaboration with the news industry gives university researchers access 
to data and professional insights. It also provides inputs for the growing 
number of AI and journalism courses.81 Inevitably, there may be culture 
clashes and any collaboration has to allow for academic issues such as 
the publication of results and ethical considerations. 
79 80
Our respondents were positive about this opportunity and some were 
already in formal or informal partnerships with higher education institutions:
We have different programs working closely with computer 
science students solving problems or building tools for us. We have 
multiple relationships with technology teams in academic 
institutions – for example in natural language processing. We also 
meet regularly with small technology companies and start-ups. 
They all help and those relationships are very useful to us. 
One advantage is the ability to work on both practical and ethical issues in 
a cross-disciplinary way:
We need to connect technical expertise to industry expertise. In 
doing that we help solve real problems and hopefully educate 
technologists about the dangers and ethics in different sectors. 
Working with universities is seen as a way of helping to promote 
understanding of journalism and AI more generally:
Universities/Journalism Schools should improve AI literacy, 
demystifying the concept and eliminating that perception of the 
technology as a threat or as a competitor to journalism itself. 
It was also seen as a good way to counterbalance the dominance  
of Big Tech:
These organisations can act as a neutral firewall between 
media houses and technology groups. 
In recent years journalists have become better at developing networks 
for discussing their work and to promote innovation and share ideas. 
Many respondents cited that kind of collaboration as a vital source of 
information on newsroom development alongside other sources such as 
industry media:
A regular dialogue about how other companies are creatively 
leveraging AI, solving problems, sharing best practices, and how to 
address challenges would be very insightful and practical. 
One outcome of this survey has already been the emergence of an 
informal network of newsroom experts that could act as a platform that 
allows this dialogue to flourish.
80
4.5 How Will AI Reshape Journalism?
This report has shown us what newsrooms are doing with AI and 
what kinds of things they would like to do in the future. We have seen 
the impact that it is already having on newsflows and relationships 
with the public and how it raises new challenges such as the role of 
the technology companies and the need for training. But how do our 
respondents see AI trends in the longer-term? The respondents to this 
report are generally engaged with AI so it is perhaps less surprising that 
they see it as critical to shaping its future:
Adopting AI is not a choice, it’s a marathon that every  
organization needs to start running if they haven’t already. 
We know from media history that technology can have both relatively 
superficial and much more profound impacts:
Technology has always affected journalism: the internet 
changed distribution; typewriters and then computers improved 
productivity; the printing press helped newspapers scale. 
Automation and AI are already changing all aspects of the 
industry and that trend will continue. 
Most of our respondents saw the future impact of AI as incremental, 
augmenting existing trends in journalism. But a minority believe 
that it will be at the heart of a more substantial transformation into 
a ‘structured’ journalism82 where the process of automation and 
personalisation drives the content creation:
AI is the technology that actually allows us to go from 
unidirectional, broadcast communications to readers, to a 
bidirectional, interactive one. 
This kind of journalism will have to be interdisciplinary around AI, and that 
means creating new skill-sets, organisational modes, and approaches to 
journalism.83 New tasks could lead to new job titles related to AI, such as 
Automation editor, Computational journalist, Newsroom tool manager, AI 
ethics editor.84 But how will what they do be different?
81 82
TEN WAYS NEWSROOMS EXPECT AI TO 
RESHAPE JOURNALISM:
1 Better personalised distribution of content
2 More efficient, automated production of content
3 Dynamic pricing both for ads and subscriptions
4 Find more stories in data; find more data in stories
5 Better automated transcriptions
6 Make content moderation manageable 
7 Fake news/deep fakes recognition
8 New tools for debunking
9 Enhanced image/video search
10 Deeper sentiment analysis on UGC
4.6 Augmentation or Transformation?
The majority of our respondents felt that AI would add to existing 
workflows or make them more efficient and effective:
“ I think any part of the newsroom could be augmented 
with AI, the real question is should it? Is it worth our time? 
Some promising areas could be... to evaluate own content, 
to make moderation of comments easier, to provide better 
recommendations, to supply better context. Areas like ‘identifying 
news stories or scoops’ could use AI but I would tread carefully, 
as the context shifts regularly, and editorial judgment is key. 
There were lots of specific ideas for imaginative uses of AI:
Automatic text to anything – text to voice, text to video – 
probably will be most useful application in the near future. 
82
But even if the impact is to augment, news media is now in a race to 
exploit the technology:
Optimizing workflows with the help of AI will be a must to 
stay competitive. To do so, news media companies will 
increasingly have to become tech companies and build up their 
own software development departments. 
Augmentation could have cumulative qualitative effects and these could 
be positive:
AI could help us to increase the depth of content of our 
articles and to include more primary sources in our research. 
The production of news content enriched with personal aspects 
via widgets also seems promising to me. 
Newsrooms have spent the last two decades dealing with expanding 
scale and increased complexity in newsgathering, production, and 
distribution. Most recently many have combined this with more focused 
but often no less complex models of customised content, subscription 
and user engagement. There have been huge shifts in revenue sources 
and audience behaviour as well as industry ‘restructuring’, with the 
loss of capacity in many areas as well as new entrants. Many of our 
respondents argue that AI will be another major force for change across 
the industry:
There is potential for complete disruption of existing workflows 
in news production and entirely new categories of news products 
(eg, automated journalism and programme assembly). It’s not yet 
certain how quick or significant this AI-driven disruption will be, 
but it probably has the potential to change the news industry 
beyond all recognition. The distribution of news content to AI-
enabled platforms, which then build on these published assets to 
create data-driven experiences, is potentially a major disruptor to 
the business models of the news industry and its ability to create 
distinct editorialised experiences. This is amplified by an industry 
structure which sees fewer platforms with significant market power. 
As of yet there is no established paradigm for the distribution of 
news in these environments. 
83 84
This vision of the future would entail a re-thinking of journalism as a 
practice and the structure of the industry:
We will all have to define much more strongly what we stand for, 
what our mission is and what tasks we can assign to systems. If we 
do not cooperate more closely, developments in AI could increase 
concentration, as smaller media houses cannot afford their own 
projects in this area. 
The news media is no longer just competing amongst itself: 
It’s about finding our place and our usefulness in a world where 
most competitors are out of the press and have far more resources 
than the information industry. 
AI may be a reform or a revolution, but will its benefits be equally 
distributed? Is AI in journalism for the many or the few?: 
As AI becomes more central to the discovery, production and 
distribution of news and information, a key question is the role of 
traditional - and resource-strapped - newsrooms in that ecosystem. 
Will they even have the tools to compete? Will they provide ‘artisanal’ 
content as feedstock for larger organizations to use in AI-driven 
news engines? What parts of the news ecosystem will remain the 
domain of newsrooms? 
One change factor that AI will help drive is the ‘journalism of things’,  
the shift of distribution onto different devices. As everyday devices become 
connected, they offer opportunities to channel new forms of journalism in 
fresh ways and contexts to consumers.85 
Francesco Marconi has described experiments 
while at the Associated Press  such as using sensors 
to gather data for journalism that open up new 
ways of news-making: “We can monitor vibration 
and noise from entertainment and political venues 
to identify the most popular songs at a concert, or 
the biggest plays of a game, or even the quotes that 
resonate the most at campaign rallies.”86
84
Drones, wearables, voice, and VR are all becoming part of news production 
and dissemination and usually it is forms of AI that make them functionable 
and scalable. This kind of augmented journalism will come in different 
forms and require new skills and creativity.87 Key to understanding this new 
kind of ‘distributed journalism’ will be data about audience behaviour: 
We wanted to transform from one side communication  
to bi-directional feedback system, and AI seems to be a way to  
help us understand the user and engage them at a very  
granular level. 
Newsrooms have become more used to the idea that their journalism  
is now more ‘networked’88 or ‘distributed’ through audience engagement, 
social media, and multi-platform dissemination.89 AI could increase  
that diversity:
I think developing increased capacity for abstraction and better 
analytical sophistication about these technologies and their 
implications in the newsroom is a necessary starting point. We 
need to increase the proportion of people in newsrooms who work 
with patterns of news rather than just with case-by-case stories. 
Yet as well as understanding data and abstraction, journalists may have 
to work even harder at the human touch. With so much tech involved 
can you still keep the human dimension and put the user at the heart of 
the experience?
I find it exciting to see whether AI can also support us in our 
interaction with readers without this having an artificial effect. 
There would be great potential here if we would make our work 
more transparent and relevant for more people. 
Key to public trust and interest in journalism is emotions.90 Users need 
to feel that journalism sees the world from their perspective, that it 
reflects their values and identity and feelings. Emotions have always 
been part of journalism as ‘human interest’ but in the digital and social 
era they are now a key element of gaining attention and promoting 
sharing and engagement. As AI becomes better at understanding 
‘sentiment’ it might be that the technology can help better connect 
newsrooms and audiences. 
85 86
4.7 What Can Newsrooms Learn from  
Other Industries?
Journalism is a peculiar industry with many special conditions to 
its work: the news cycle, public interest, regulatory regimes, multiple 
business models, multiple formats, highly differentiated audiences and 
varied but strong ‘professional’ cultures. It prizes independence for both 
ethical and commercial reasons. So some of our respondents (about 
10 per cent) felt it need not spend too much time looking at what other 
industries do with AI:
I’d rather [prefer] that we thought VERY particularly about 
ourselves in this space. 
However, the majority view was that the news media has been  
too insular:
I think journalism should look at ALL other industries. In 
fact, I worry that journalism as an industry looks too often for 
guides within journalism itself. What is the New York Times 
doing? What is the Washington Post doing? We need to look at 
other industries and see how their innovations, stumbles, and 
concerns could apply to us. 
Some of our respondents have careers that involved working in other 
industries and many suggested that there are continuing lessons to 
be learnt by looking beyond the news media. Calls for the creation of a 
‘Spotify for News’ or a ‘Netflix for Journalism’ have become clichés but 
comparisons can be instructive . Those are the new companies that have 
made the most of the affordances of AI technologies. But respondents 
also looked to legacy industries that have restructured themselves and 
turned technology-driven threats into more sustainable models:
If we take a long-term view, we should look to any industry 
with supply chain management problems. For example, the music 
industry from 20 years ago. 
Clearly, media sectors like advertising and marketing are closely related 
to the news industry but other less obvious industries were cited such 
as online retail companies such as Ebay, Amazon, and Alibaba:
86
Online retail is an industry that has already deeply 
integrated AI into its automated processes. This is partly due to 
the fact that online retail generates large amounts of highly 
structured data, which makes the deep analysis of user behaviour 
as well as advanced targeting a lot easier. Even though the 
media industry might not be able to copy the techniques employed 
in online retail one-to-one, it is definitely worthwhile to look at 
the state-of-the-art machine learning models used for product 
recommendation, dynamic pricing, customer journey analysis 
and even automated product description / title generation. 
Even the gambling industry could offer lessons in how to use technology 
to understand audiences:
The betting websites are really interesting to look to, they track 
behaviour more than any other industries (influence on getting 
hooked), and that is what we want to do really – better to be 
hooked to local news. 
Some of the cleverest adoptions of new technology for fresh content 
formats has been in gamification, such as the Financial Times ’ Uber 
Game,91 but our respondents saw wider relevance in the gaming industry:
Personally I look to the gaming industry as a plethora of best 
practice in the field of different formats of AI employment. What 
stands out as particularly impressive is the seamless implementation 
of AI into the HCI [Human-Computer Interaction]. 
Comparisons can give positive and negative lessons. Law for example 
has benefited from AI-powered data search, but AI has also had 
an impact on legal labour patterns. The lessons are not just about 
techniques or economics. AI in other industries is provoking a whole 
new debate about what trust means when the relationship with the user 
is automated.92 Medicine, pharmaceuticals, and biotech industries are 
all facing profound ethical challenges that journalism should consider:
87 88
We should look to them for the standards they uphold, in 
terms of data precision, verification, data integrity, and the 
anonymised large pools of data used. 
But the most common reference was to the technology companies. 
They dominate this space in terms of research. They are creating new 
products and networks that journalists might use. They are also facing 
market and ethical challenges that journalism can learn from:
Software giants and digital tech like Microsoft, Google, and 
Facebook are the leading example in this area and we need to 
learn and learn and learn from them. 
Tech companies are an obvious example – they make a lot of 
errors and assumptions we can learn from and avoid. 
The news industry has proved remarkably resilient and adaptable in the 
face of technological change through recent history. Yet it continues to 
shrink in size and struggle for resources. 
According to our respondents, AI promises yet more change with huge 
challenges as well as opportunities for those able to understand and 
deploy it to enhance their work. But journalism is a relatively small 
business and AI is a big and expensive technology. News organisations 
will once more have to show imagination as well as determination if the 
AI-powered augmented journalism is to thrive.
88
This report represents the views of a large sample of people working 
with AI in a variety of news organisations across the world. The 
respondents tended to be familiar with AI and have a positive approach 
to its adoption. So it is even more interesting when they point out the 
limits of AI and the need for much more effort to make it work well. 
They demonstrate that AI is giving them more power, but with that come 
editorial and ethical responsibilities.
The respondents strongly believe that AI is there to make journalists 
more efficient and to increase capacity to do two key things:
1  To free up journalists to work, with or without AI, on creating 
better journalism at a time when the news industry is fighting for 
economic sustainability and for public trust and relevance. 
2  To help the public cope with a world of news overload and 
misinformation and to connect them in a convenient way to credible 
content that is relevant, useful and stimulating for their lives.
To do this, news organisations have to change (again). They need to 
adopt some form of AI strategy. They need to change their workflows, 
systems, and recruitment. 
Even then, it’s going to be tough. This is an emerging technology that 
can be complex and expensive to apply. It has some serious downsides 
in terms, for example, of algorithmic bias or the temptation towards 
short-term financial gains. Some of the challenges go beyond individual 
organisations. As an industry there has to be more internal and external 
collaboration. Newsrooms need to make serious investments to attract 
the skills, knowledge, and innovation that journalism needs to optimise 
the opportunities of AI and reduce the potential harms.
90 89Conclusion  
What Does AI Mean  
for Journalism?This will require a change in thinking from an industry that has always 
been ultra-competitive and relatively insular. It will demand a degree 
of flexibility and long-term planning that can go against the priorities 
of the news cycle and the pressures of the market-place. The public 
media sector will face a similar challenge to adapt itself. The news 
media will need a robust but pragmatic approach to dealing with other 
stakeholders such as the technology companies.
AI technologies will not save journalism or kill it off. Journalism 
faces a host of other challenges such as public apathy and antipathy, 
competition for attention, and political persecution.
Perhaps the best hope for journalism in a world where AI becomes more 
powerful in so many areas, from politics to medicine, is that AI and the 
world need good journalism more than ever. To misquote President 
Kennedy, newsrooms should not just be asking what AI can do for them, 
they should be asking what they can do for an AI world.
First of all, they need to get their AI act together. This does not mean 
succumbing to the hype. It means making informed judgements about 
the value of this technology and the way it can be deployed strategically. 
It means accepting that, once again, news organisations will have to 
adjust to the fact that what journalism is and how it is consumed, is 
changing. The ‘vision thing’ still matters for journalism, especially while 
the world around it appears to be more confused and conflicted.
AI offers a range of tools for journalism. Not to re-establish its 
preeminence as the information gatekeeper. But instead to find new 
ways of being the creator and curator of credible information; a source 
of critical and independent analysis; and a forum for diverse and relevant 
public debate.93 As Clay Shirky said over a decade ago, “there is no 
such thing as information overload, there’s only filter failure”.94 Human 
journalistic skills and values combined with these technologies can help.
90Newsrooms can’t do this alone. We don’t know enough about what is 
happening with algorithms and the new networks of communication.95 
We need to understand better how AI is shaping the information 
ecosystem for new generations of citizens.96 News organisations need 
to find ways to tap into the resources and expertise of others. They need 
to make the case to the public and society that journalism can be a 
critical factor in the healthy development of this technology. 
Perhaps the biggest message we should take from this report is  
that we are at another critical historical moment. If we value journalism 
as a social good, provided by humans for humans, then we have a 
window of perhaps 2-5 years, when news organisations must get across 
this technology. The good news that we take from the responses to  
our survey, is that a significant part of the global journalism industry  
is facing up to that challenge and working hard to make it happen.  
They are enthusiastic about the new powers, but also accept the  
new responsibilities.
For our part, Polis looks forward to helping create a network for 
journalism and AI that can improve communications for all interested 
parties and help foster better training, stimulate research and the 
exchange of best practice and dialogue. 
Professor Charlie Beckett  
LSE, November 2019
91 92Ad targeting :
“An advertisement technique where advertisements are placed in specific areas 
of the screen to increase visibility and ‘clickability’ or to give tailor-made ads 
based on the user’s past behaviors and preferences. Targeted ads are meant 
to reach certain customers based on demographics, psychographics, behavior 
and other second-order activities that are learned usually through data exhaust 
produced by users themselves”. ( https://www.techopedia.com/definition/30295/
ad-targeting ) Ad targeting is extremely relevant in the context of social media feeds 
and recommendation engines, with “micro targeted” ads built around each user’s 
specific preferences, embodied in their individual online data trail (likes, comments, 
shares, uploads, searches etc). For more on “micro targeting”, see: https://blog.
mozilla.org/internetcitizen/2018/10/04/microtargeting-dipayan-ghosh/
Algorithm: 
“A procedure for solving a mathematical problem in a finite number of steps 
that frequently involves repetition of an operation”. More broadly, “a step-by-step 
procedure for solving a problem or accomplishing some end.’’ ( https://www.
merriam-webster.com/dictionary/algorithm ) 
Artificial intelligence (AI): 
“A collection of ideas, technologies, and techniques that relate to a computer 
system’s capacity to perform tasks normally requiring human intelligence.” 
(https://reutersinstitute.politics.ox.ac.uk/our-research/industry-led-debate-how-
uk-media-cover-artificial-intelligence ) As the Definition section in this report 
states, this is a nebulous term used by different people to mean different things.
Automation: 
“The technique, method, or system of operating or controlling a process by highly 
automatic means, as by electronic devices, reducing human intervention to a 
minimum.” ( https://www.dictionary.com/browse/automation ). “The creation of 
technology and its application in order to control and monitor the production and 
delivery of various goods and services. It performs tasks that were previously 
performed by humans. Automation is being used in a number of areas such as 
manufacturing, transport, utilities, defense, facilities, operations and lately, information 
technology.” ( https://www.techopedia.com/definition/32099/automation ) 
92Glossary
GlossaryBias: 
A systematic prejudice or error affecting the rationality and fairness of a decision. 
Rooted in decision theory, cognitive psychology and statistics, the notion of bias 
is extremely important as both journalism and artificial intelligence techniques 
ultimately rely on human decisions, and are as such subject to “cognitive” biases 
(confirmation bias, bandwagon effect, etc.). When mirrored in bad, incomplete 
or flawed data sets to train AI algorithms, this may result in equally flawed AI-
powered decisions: “Algorithms can have built-in biases because they are created 
by individuals who have conscious or unconscious preferences that may go 
undiscovered until the algorithms are used, and potentially amplified, publically.” 
(https://searchenterpriseai.techtarget.com/definition/machine-learning-bias-
algorithm-bias-or-AI-bias ) 
Bot:
‘Bot’ is short for ‘Robot’ and usually refers to ‘agent-like’ software – ie, software 
that exhibits autonomy or autonomous characteristics. A bot is “a piece 
of software that can execute commands, reply to messages, or perform 
routine tasks, as online searches, either automatically or with minimal human 
intervention” ( https://www.dictionary.com/browse/bot ). Bots perform either 
perfectly legitimate (eg. smart assistants, search engine spiders) and malicious 
activities (eg., covertly spread false information and political propaganda in 
coordination with other bots, within a so-called “botnet”). For more see:  
https://www.techopedia.com/definition/24063/internet-bot
CMS: 
Acronym for “Content Management System”, it is “a software application  
or set of related programs used to create and manage digital content.”  
(https://searchcontentmanagement.techtarget.com/definition/content-
management-system-CMS )
CPM: 
Technically “cost per mille”, it is a common measure in advertising indicating  
the cost per thousand impressions of an ad.
94 93Data analytics:
Analytics is essentially just the counting digital actions and e vents, and drawing 
conclusions from those counts.  “Data analytics is the pursuit of extracting 
meaning from raw data using specialized computer systems. These systems 
transform, organize, and model the data to draw conclusions and identify 
patterns.” ( https://www.informatica.com/services-and-training/glossary-of-terms/
data-analytics-definition.html#fbid=Ne5BLlzmG0q ); Many of the techniques and 
processes of data analytics have been automated into mechanical processes 
and algorithms that work over raw data for human consumption. Data analytics 
techniques can reveal trends and metrics that would otherwise be lost in the 
mass of information.” ( https://www.investopedia.com/terms/d/data-analytics.
asp); Ever increasing computing power and automated analyzing capabilities 
are exponentially expanding the volume of data sets that can be processed for 
meaning and trends, leading experts in the field to coin a new term, “Big Data”.
Deepfake : 
This is the negative form of a broader concept of ‘synthetic media’.  Audio 
and video altered through machine learning and deep learning techniques 
for maximum, real-time realism in fakery. The term originally comes from a 
Reddit user that, in 2017, used such techniques to realistically and dynamically 
add faces of celebrities to pornographic content ( https://www.theverge.
com/2018/5/22/17380306/deepfake-definition-ai-manipulation-fake-news ), 
and is now widely used for any kind of content, the politically charged included. 
(https://www.theguardian.com/technology/ng-interactive/2019/jun/22/the-rise-
of-the-deepfake-and-the-threat-to-democracy )
Deep learning: 
“Deep learning is a subset of machine learning in artificial intelligence (AI) that 
has networks capable of learning unsupervised from data that is unstructured 
or unlabeled. Also known as deep neural learning or deep neural network” 
(https://www.investopedia.com/terms/d/deep-learning.asp ), it is one of the 
most advanced contemporary applications of “AI”, powering a broad range of 
image, voice and text recognition tools. ( https://blogs.scientificamerican.com/
observations/a-deep-dive-into-deep-learning/ )
Dynamic pricing: 
When the price of a product or service changes according to market demands: 
the most familiar examples are airline seats and hotel rates. One example is 
“surge pricing” policies for ride-sharing applications such as Uber or Lyft, in which 
the price of a ride increases with its demand. The better the market knows its 
users, possibly through advanced data analytics techniques, the better it can 
design the dynamics of its pricing according to their habits and needs. ( https://
www.thestreet.com/technology/lyft-vs-uber-14791376 )
94Fake news: 
An academically discredited and yet widely used term that encompasses the 
whole spectrum of meanings related to untruths, from misinformation (ie, non 
deliberate manipulation) to disinformation (ie, deliberate lying), from half-truths to 
plain lies. Its usage is mostly related to false information spread on social media, 
possibly by covert/anonymous agents of broader propaganda campaigns in a 
coordinated fashion. The expression has also been widely adopted by autocrats 
and demagogues alike in order to discredit adversarial journalism and political 
oppositions. ( https://www.poynter.org/fact-checking/2018/reporters-stop-calling-
everything-fake-news/ ; https://www.nytimes.com/2017/12/12/world/europe/
trump-fake-news-dictators.html ) 
Filter bubble: 
Coined by activist Eli Pariser in a 2011 bestseller of the same name, the “Filter 
Bubble” hypothesis states that social media are increasingly indoctrinating 
us with our own propaganda, algorithmically exposing us only to content that 
is consistent with our current ideological preferences, while at the same time 
“hiding” whatever source could lead us to challenge our own beliefs, preferences 
and habits. This would respond to their business model’s utmost imperative: 
hook the user with more of whatever it is that hooked him since. Since its 
conception, the notion has been increasingly challenged academically. For a 
roundup of available literature, see: https://cristianvaccari.com/2018/02/13/how-
prevalent-are-filter-bubbles-and-echo-chambers-on-social-media-not-as-much-as-
president-obama-thinks/  
Machine learning (ML): 
“Machine learning is an application of artificial intelligence (AI) that provides 
systems the ability to automatically learn and improve from experience without 
being explicitly programmed” ( https://www.expertsystem.com/machine-learning-
definition/ ). Definitions, however, abound. Here is how Turing Award winner and 
father of deep learning, Yoshua Bengio, puts it: “Machine learning research is part 
of research on artificial intelligence, seeking to provide knowledge to computers 
through data, observations and interacting with the world. That acquired 
knowledge allows computers to correctly generalize to new settings”.  
(https://emerj.com/ai-glossary-terms/what-is-machine-learning/ )
95 96
Metadata : 
A set of data that describes and gives information about other data. “For example, an 
image may include metadata that describes how large the picture is, the color depth, 
the image resolution, when the image was created, and other data. A text document’s 
metadata may contain information about how long the document is, who the author 
is, when the document was written, and a short summary of the document. Web 
pages often include metadata in the form of meta tags. Description and keywords 
meta tags are commonly used to describe the Web page’s content. Most search 
engines use this data when adding pages to their search index.” ( https://techterms.
com/definition/metadata ). The automation of this “meta-tagging” function is among 
the most common experimentations in journalism AI described in our report.
Minimum viable product : 
“A minimum viable product (MVP) is a development technique in which a new 
product or website is developed with sufficient features to satisfy early adopters. The 
final, complete set of features is only designed and developed after considering the 
feedback from the product’s initial users.
This concept has been popularized by Eric Ries, a consultant and writer on start-ups.” 
(https://www.techopedia.com/definition/27809/minimum-viable-product-mvp )
MOOC : 
A Massive Open Online Course (MOOC) is “a free Web-based distance learning 
program that is designed for the participation of large numbers of geographically 
dispersed students” ( https://whatis.techtarget.com/definition/massively-open-
online-course-MOOC ). Coined in 2008 by Dave Cormier, the term implies, to some, 
an opportunity for restructuring education through personalisation and remote 
attendance; to others, this amounts to mere hype instead. ( https://www.theguardian.
com/education/2014/jan/20/moocs-global-thirst-education , https://www.
theguardian.com/higher-education-network/blog/2012/aug/08/mooc-coursera-
higher-education-investment ) 
Natural language processing : 
“Natural Language Processing, usually shortened as NLP , is a branch of artificial 
intelligence that deals with the interaction between computers and humans using 
the natural language. The ultimate objective of NLP is to read, decipher, understand, 
and make sense of the human languages in a manner that is valuable. Most NLP 
techniques rely on machine learning to derive meaning from human languages.” 
(https://becominghuman.ai/a-simple-introduction-to-natural-language-processing-
ea66a1747b32 ) It is the technological foundation for many current experimentations 
with artificial intelligence in journalism, as highlighted in our report.
96
Neural network : 
“A program or system which is modelled on the human brain and is designed to 
imitate the brain’s method of functioning, particularly the process of learning” 
(https://www.collinsdictionary.com/dictionary/english/neural-network ); “a 
computer architecture in which a number of processors are interconnected in a 
manner suggestive of connections between neurons in a human brain and which 
is able to learn by a process of trial and error.” ( https://www.merriam-webster.
com/dictionary/neural%20network )
Profiling:  
In the context of journalism and AI, profiling is  the collection of information about 
users in order to be able to individually and collectively describe them, categorize 
them and serve them personalised content and advertisements. The meaning of 
the term “profiling”, however, is tied to criminal investigations. ( https://dictionary.
cambridge.org/dictionary/english/profiling )
Tagging: 
See “Metadata”
UGC content: 
User Generated Content.
97 98
Preface 
1 Bathke, B., (2017). “Journalists will have superpowers” Futurist Amy Webb talks 
opportunities — and pitfalls — of journalism tech. Medium , [online] 12 January 
2017. Available from: https://medium.com/global-editors-network/journalists-
will-have-superpowers-futurist-amy-webb-talks-opportunities-and-pitfalls-of-
97409133ea50  [19 October 2019]. 
Introduction
2 Google News Initiative.,(n.d). [online]. Available from: https://newsinitiative.
withgoogle.com/  [19 October 2019].
3 Polis (n.d)., [online]. Available from: https://blogs.lse.ac.uk/polis/   
[10 October 2019]
4 Wiggers, K., (2018). Geoffrey Hinton and Demis Hassabis: AGI is nowhere close 
to being a reality. Venture Beat , [online] 17 December 2018. Available from: https://
venturebeat.com/2018/12/17/geoffrey-hinton-and-demis-hassabis-agi-is-
nowhere-close-to-being-a-reality/  [Last accessed 19 October 2019].
5 Jajal, T.D., (2018). Distinguishing between Narrow AI, General AI and Super AI. 
Medium , [online] 21 May 2018. Available from: https://medium.com/@tjajal/
distinguishing-between-narrow-ai-general-ai-and-super-ai-a4bc44172e22  [Last 
accessed 19 October 2019]
6 Brennen, J.S., Howard, P .N. and Nielsen, R.K., (2018). An Industry-Led Debate: 
How UK Media Cover Artificial Intelligence. Reuters Institute for the Study of 
Journalism Fact Sheet,(December) , pp1-10.
7 Corea, F., (2018). AI Knowledge Map: how to classify AI technologies. Medium , 
[online] 29 August 2019. Available from: https://medium.com/@Francesco_AI/ai-
knowledge-map-how-to-classify-ai-technologies-6c073b969020  [Last accessed 
19 October 2019].
8 Diakopoulos, N., (2019). Automating the News: How Algorithms Are Rewriting the 
Media . Harvard University Press. pp16. 
9 Elements of AI., (n.d). How should we define AI? [online]. Available from:  
https://course.elementsofai.com/1/1  [19 October 2019].
EndnotesEndnotes
9810 Diakopoulos, N., (2019). Automating the News: How Algorithms Are Rewriting the 
Media . Harvard University Press. pp17. 
11 Diakopoulos, N., (2019). Automating the News: How Algorithms Are Rewriting the 
Media . Harvard University Press. pp13-40. 
Chapter 1
12 Russell, A., (2011). Networked: A contemporary history of news in transition . Polity.
13 Chadwick, A., (2017). The hybrid media system: Politics and power . Oxford 
University Press.
14 Roman, E., (2019). Journalism and AI team up to measure missing stories.  
Google News Initiative, [online] 12 June 2019. Available from: https://www.blog.
google/outreach-initiatives/google-news-initiative/journalism-and-ai-team-
measure-missing-stories/  [19 October 2019].
15 Funke, D., (2018). In Argentina, fact-checkers latest hire is a bot. Poynter , 
[online] 11th January 2018. Available from: https://www.poynter.org/fact-
checking/2018/in-argentina-fact-checkers%C2%92-latest-hire-is-a-bot/   
[Last accessed 19 October 2019]. 
16 Full Fact., (n.d.). Automated Factchecking [online]. Available from: https://fullfact.
org/automated  [Last accessed 10 October 2019].
17 Marconi, F., (2020). [Forthcoming]. Newsmakers: Artificial Intelligence and the 
Future of Journalism . Columbia University Press. 
18 Koponen, J., (2018). First in the world: Yle’s smart news assistant 
Voitto ensures that you don’t miss the news you want to read. YLE by 
Newslab, [online] 10 October 2018. Available from: https://newslab.yle.fi/
blog/16T3d1e7YcuwguOk8gsq8s  [Last accessed 19 October 2019]. 
19 Sky News., (2018). Who’s Who. Sky News , [online] 19 May 2018. Available from: 
https://news.sky.com/whoswho  [Last accessed 19 October 2019]. 
20 Le Monde., (2015). Robots at Le Monde during the departmental elections? 
Yes... and no. Le Monde , [online] 23 March 2015. Available from: https://www.
lemonde.fr/le-monde/article/2015/03/23/des-robots-au-monde-pendant-les-
elections-departementales-oui-et-non_5995670_4586753.html   
[Last accessed 19 October 2019].
21 Waddell, K., (2019). AI learns to write headlines (but not this one). Axios , 
[online] 17 May 2019. Available from: https://www.axios.com/ai-learns-write-
headlines-e578a9ba-1e29-4b15-a809-22437e9691ea.html  [Last accessed 19 
October 2019].
22 Beckett, S., (2015). Robo-journalism: How a computer describes a sports match. 
BBC News , [online] 12 September 2015. Available from: https://www.bbc.co.uk/
news/technology-34204052  [Last accessed 19 October 2019].
99 100
23 T obitt, C., (2019). PA’s ‘robot-written’ story service gets first paying subscribers 
after trial ends. Press Gazette, [online] 9 April 2019. Available from: https://www.
pressgazette.co.uk/press-association-robot-written-story-service-radar-signs-up-
first-regional-press-subscribers/  [Last accessed 19 October 2019].
24 E vershed, N., (2019). Why I created a robot to write news stories. The Guardian, 
[online] 1 February 2019. Available from: https://www.theguardian.com/
commentisfree/2019/feb/01/why-i-created-a-robot-to-write-news-stories  
[Last accessed 19 October 2019]. 
25 Str ay, J., 2019. Making Artificial Intelligence Work for Investigative Journalism. 
Digital Journalism , pp.1-22.
26 T exty., (n.d.) Leprosy of the land [online]. Available from: http://texty.org.
ua/d/2018/amber_eng/  [Last accessed 19 October 2019]. 
27 Bondar enko, A., Kelm, N., Kulchynsky, R., Romanenko, N., & Tymoshchuk, Y. We’ve 
got bad news! Texty.org,  [online] 28 November 2018. Available from: http://texty.
org.ua/d/2018/mnews/eng/ [Last accessed 19 October 2019].
28 T exty.org (n.d.). Barge of memes [online]. Available from: http://texty.org.ua/d/
barzha/ [Last accessed 19 October 2019]. 
29 Reuters., (2019). Tidal investigated by Norwegian police over inflated streaming 
allegations. The Guardian, [online] 14 January 2019. Available from: https://www.
theguardian.com/music/2019/jan/14/jay-z-tidal-investigated-by-norwegian-police-streaming  [Last accessed 19 October 2019].
30 Car vajal, R., (2018). How machine learning is revolutionizing journalism.  
International Consortium of Investigative Journalists , [online] 22 August 2018. 
Available from: https://www.icij.org/blog/2018/08/how-machine-learning-is-
revolutionizing-journalism/  [Last accessed 19 October 2019]
31 Quar tz AI Studio (n.d.) Available from: https://qz.ai/ [19 October 2019].
32 Southern, L., (2019). H ow The Times of London increased digital subscribers 19% 
in a year. Digiday, [online] 15 August 2019. Available from: https://digiday.com/
media/how-the-times-of-londons-year-long-content-review-fuelled-its-drive-to-
300000-subscribers/  [Last accessed 19 October 2019]. 
33 Zaffar ano, F., (2019). How Neue Zürcher Zeitung increased its conversion rate up 
to five times with dynamic ‘paygates’. Journalism.co.uk, [online] 7 March 2019. 
Available from: https://www.journalism.co.uk/news/how-nzz-increased-its-conversion-rate-up-to-five-times-with-dynamic-paygates-/s2/a735623/   
[19 October 2019]
34 W ang, S., (2018). After years of testing, The Wall Street Journal has built a 
paywall that bends to the individual reader. NiemanLab,  [online] 22 February 2018. 
Available from: https://www.niemanlab.org/2018/02/after-years-of-testing-the-wall-street-journal-has-built-a-paywall-that-bends-to-the-individual-reader/   
[19 October 2019]. 
100
35 Moses. L., (2017). The Washington Post’s robot reporter has published 850 
articles in the past year. Digiday , [online] 14 September 2017. Available from: 
https://digiday.com/media/washington-posts-robot-reporter-published-500-
articles-last-year/  [19 October 2019]. 
36 Granger, J., (2018) Press Association’s news service RADAR has written 
50,000 individual local news stories in three months with AI technology. 
Newsrewired, [online] 7 November 2018. Available from: https://www.
newsrewired.com/2018/11/07/press-associations-news-service-radar-
has-written-50000-individual-local-news-stories-in-three-months-with-ai-
technology/  [19 October 2019]. 
37 Kunova, M., (2019). The Times employs an AI-powered ‘digital butler’ 
JAMES to serve personalised news. Journalism.co.uk, [online] 24 May 2019. 
Available from: https://www.journalism.co.uk/news/the-times-employs-an-ai-
powered-digital-butler-james-to-serve-personalised-news/s2/a739273/   
[19 October 2019]. 
38 Mullin, B., (2016). Bloomberg EIC: Automation is ‘crucial to the future of 
journalism’. Poynter , [online] 27 April 2016. Available from: https://www.poynter.
org/tech-tools/2016/bloomberg-eic-automation-is-crucial-to-the-future-of-
journalism/  [19 October 2019]. 
39 Broussard, M., and Lewis, S., (2019). Will AI Save Journalism — or Kill It?  
Knowledge@Wharton,  [online] 9 April 2019. Available from: https://knowledge.
wharton.upenn.edu/article/ai-in-journalism/  [19 October 2019]. 
40 Chun Chew, W., (2018). A Look at Toutiao: China’s Artificial Intelligence Powered 
News Platform. Medium, 1 December 2018. Available from: https://medium.
com/@chewweichun/a-look-at-toutiao-chinas-artificial-intelligence-powered-
news-platform-4eef3c23b79a  [19 October 2019]. 
41 DeepL Pro., (n.d). Available from: https://www.deepl.com/pro-faq.html   
[19 October 2019]. 
42 Spangher, A., (2018). How Does This Article Make You Feel? Medium , [online]  
31 October 2018. Available from: https://open.nytimes.com/how-does-this-article-
make-you-feel-4684e5e9c47  [19 October 2019]. 
43 Texty., (n.d.) Leprosy of the land [online]. Available from: http://texty.org.
ua/d/2018/amber_eng/  [19 October 2019]. 
44 Koponen, J., (2018). First in the world: Yle’s smart news assistant 
Voitto ensures that you don’t miss the news you want to read. YLE by 
Newslab, [online] 10 October 2018. Available from: https://newslab.yle.fi/
blog/16T3d1e7YcuwguOk8gsq8s  [19 October 2019]. 
101 102
Chapter 2
45 Rogati, M., (2017). The AI Hierachy of Needs. Hacker Noon , [online] 12 June 2017. 
Available from: https://hackernoon.com/the-ai-hierarchy-of-needs-18f111fcc007  
[19 October 2019]. 
46 Shipman, A., (2019). Good Strategy Bad Strategy. Anna Shipman,  [online] 17 May 
2019. Available from: https://www.annashipman.co.uk/jfdi/good-strategy-bad-
strategy.html  [19 October 2019]. 
47 Marconi, F., (2020). [Forthcoming]. Newsmakers: Artificial Intelligence and the 
Future of Journalism . Columbia University Press. 
48 Nieman Lab., (2019). How The Wall Street Journal is building an incubator into 
its newsroom, with new departments and plenty of hires. Nieman Lab, [online] 12 
August 2019. Available from: https://www.niemanlab.org/2019/08/how-the-wall-
street-journal-is-building-an-incubator-into-its-newsroom-with-new-departments-
and-plenty-of-hires/  [19 October 2019]. 
Chapter 3
49 Bell, V., (2010). Don’t Touch That Dial! Slate, [online] 15 February 2010. Available 
from: https://slate.com/technology/2010/02/a-history-of-media-technology-
scares-from-the-printing-press-to-facebook.html  [19 October 2019]. 
50 Beckett, C., (2018). The Evolution of ‘Quality’ Journalism. Medium , [online] 5 June 
2018. Available from: https://medium.com/s/story/what-is-quality-journalism-
here-it-is-and-here-s-how-we-do-it-5a2c0634ee51  [19 October 2019].
51 Fletcher, R., Newman, N., Nielsen, R.K., and Kalogeropoulos, A., (2019). Reuters 
Institute Digital News Report 2019. Reuters Institute for the Study of Journalism 
[online]. Available from: https://reutersinstitute.politics.ox.ac.uk/sites/default/
files/2019-06/DNR_2019_FINAL_0.pdf  [19 October 2019]
52 Illing, S., (2019). How search engines are making us more racist. Vox, [online]  
6 April 2018. Available from: https://www.vox.com/2018/4/3/17168256/google-
racism-algorithms-technology  [19 October 2019]. 
53 alphaHoo., (2019). Will AI cause mass unemployment? Medium, [online] 29 May 
2019. Available from: https://chatbotslife.com/will-ai-cause-mass-unemployment-
f26537e5f25a  [19 October 2019]. 
54 McCourtie, S. D., (2018). With AI, jobs are changing but no mass unemployment 
expected – UN labour experts. UN News  [online] 4 September 2018. Available 
from: https://news.un.org/en/story/2018/09/1018292  [19 October 2019]. 
55 Diakopoulos, N., and Friedler, S., (2016). How to Hold Algorithms Accountable. 
MIT Technology Review , [online] 17 November 2016. Available from: https://
www.technologyreview.com/s/602933/how-to-hold-algorithms-accountable/  
[19 October 2019]. 
102
56 Bernstein, C., and Rouse, M., (2018). machine learning bias (algorithm bias or 
AI bias). Search Enterprise AI, [online] October 2018]. Available from: https://
searchenterpriseai.techtarget.com/definition/machine-learning-bias-algorithm-
bias-or-AI-bias  [19 October 2019]. 
57 Jiaconda., (2019). Understanding and Reducing Bias in Machine Learning. 
Medium, [online] 5 April 2019. Available from: https://towardsdatascience.com/
understanding-and-reducing-bias-in-machine-learning-6565e23900ac   
[19 October 2019].
58 Diakopoulos, N., (n.d.) Algorithmic Accountability & Transparency. Available from: 
http://www.nickdiakopoulos.com/projects/algorithmic-accountability-reporting/  
[19 October 2019].
59 Vaccari, C., (2018). How Prevalent are Filter Bubbles and Echo Chambers 
on Social Media? Not as Much as Conventional Wisdom Has It. Cristian 
Vaccari,  [online] 13th February 2019. Available form: https://cristianvaccari.
com/2018/02/13/how-prevalent-are-filter-bubbles-and-echo-chambers-on-social-
media-not-as-much-as-president-obama-thinks/  [19 October 2019].
60 Jarvis, J., (2019). Evidence, Please.  Medium,  [online] 11th October 2019. 
Available from: https://medium.com/whither-news/evidence-please-
d794b5d21ee4  [19 October 2019].
61 LSE Truth, Trust, and Technology Commission. (n.d.) Available from: http://www.
lse.ac.uk/media-and-communications/truth-trust-and-technology-commission  
[19 October 2019]
62 First Draft News., (n.d.) Available from: https://firstdraftnews.org/   
[19 October 2019]
63 The Trust Project., (n.d.) Available from: https://thetrustproject.org/   
[19 October 2019]. 
64 Online News Association, (n.d). ONA Social Newsgathering Ethics Code. 
Journalists.org,  [online]. Available from: https://journalists.org/tools/social-
newsgathering/#m3edu  [11th October 2019]. 
65 Bradshaw, P ., (2019). If we are using AI in journalism we need better guidelines on 
reporting uncertainty. Online Journalism Blog , [11th October 2019]. Available from: 
https://onlinejournalismblog.com/2019/05/23/ai-in-journalism-guidelines-on-
reporting-uncertainty/  [19 October 2019]. 
66 Liberty, J., (2019). Studying the behaviour of AI. MIT Media Lab, [online] 11th 
October 2019. Available from: https://www.media.mit.edu/posts/studying-the-
behavior-of-ai/  [19 October 2019]. 
67 Myles, S., (2018). How Can We Make Algorithmic News More Transparent? 
Slideshare , [online] 22 May 2018. Available from: https://www.slideshare.net/
smyles/how-can-we-make-algorithmic-news-more-transparent-98053867   
[19 October 2019]. 
103 104
68 Isaac, M., (2019). In New Facebook Effort, Humans Will Help Curate Your News 
Stories. NY Times, [online] 20 August 2019. Available from: https://www.nytimes.
com/2019/08/20/technology/facebook-news-humans.html   
[19 October 2019]. 
69 Nilsson, P ., (2019). Google adjusts search algorithm to boost original journalism. 
Financial Times, [online] 12 September 2019. Available from: https://www.ft.com/
content/e27ca6c6-d57c-11e9-a0bd-ab8ec6435630  [19 October 2019]. 
70 Adams, C. J., New York Times: Using AI to host better conversations. Google 
Technology, [online] 23 May 2018. Available from: https://www.blog.google/
technology/ai/new-york-times-using-ai-host-better-conversations/   
[19 October 2019]
71 Lewis, S.C., Guzman, A.L. and Schmidt, T.R., 2019. Automation, Journalism, 
and Human–Machine Communication: Rethinking Roles and Relationships of 
Humans and Machines in News. Digital Journalism , pp.1-19.
72 Carlson, M., 2017. Journalistic authority: Legitimating news in the digital era . 
Columbia University Press.
73 Hern, A., (2019). New AI fake text generator may be too dangerous to release, 
say creators. The Guardian, [online] 14 February 2019. Available from: https://
www.theguardian.com/technology/2019/feb/14/elon-musk-backed-ai-writes-
convincing-news-fiction  [19 October 2019]. 
74 Schuster, E., (2018). We need to talk! About artificial intelligence and ethics in 
journalism. LinkedIn, [online] 1 November 2019. Available from: https://www.
linkedin.com/pulse/we-need-talk-artificial-intelligence-ethics-ellen-schuster/   
[19 October 2019]. 
75 AI Ethics Initiative., (2018). Meet the 66 finalists in the AI and the News Open 
Challenge. AI News Initiative, [online] 4 December 2018. Available from: https://
aiethicsinitiative.org/news/2018/12/3/meet-the-66-finalists-in-the-ai-and-the-
news-open-challenge  [19 October 2019]. 
Chapter 4
76 Waters, R., (2019). The billion-dollar bet to reach human-level AI.  Financial Times, 
[online] 3 August 2019. Available from: https://www.ft.com/content/c96e43be-
b4df-11e9-8cb2-799a3a8cf37b  [19 October 2019]. 
77 MIT Technology Review., (2019). The Man Who Helped Invent Virtual Assistants 
Thinks They’re Doomed Without a New A.I. Approach. Medium , [online] 14 March 
2019. Available from: https://medium.com/mit-technology-review/the-man-
who-helped-invent-virtual-assistants-thinks-theyre-doomed-without-a-new-a-i-
approach-34654ad1054d  [19 October 2019]. 
78 Bryant, H., (2018). A look at nine of the best collaborative journalism projects of 
2018. Medium , [online] 17 December 2018. Available from: https://medium.com/
centerforcooperativemedia/a-look-at-nine-of-the-best-collaborative-journalism-
projects-of-2018-cfd49b3c4865  [19 October 2019]. 104
79 The Panama Papers., (n.d.) International Consortium of Investigative Journalists. 
Available from: https://www.icij.org/investigations/panama-papers/   
[19 October 2019]. 
80 Wash Post PR Blog., (2019). The Washington Post establishes a computational 
political journalism R&D lab to augment its campaign 2020 coverage. 
The Washington Post,  [online] 24 July 2019. Available from: https://www.
washingtonpost.com/pr/2019/07/24/washington-post-establishes-
computational-political-journalism-rd-lab-augment-its-campaign-coverage/   
[19 October 2019]. 
81 Lehigh University., (2019). Rise of the robots: Coming to a first-year Intro to 
Journalism class near you. Phys.org  [online] 1 July 2019. Available from: https://
phys.org/news/201907-robots-first-year-intro-journalism-class.html   
[19 October 2019]. 
82 Jones, R. and Jones, B., 2019. Atomising the News: The (In) Flexibility of 
Structured Journalism. Digital Journalism , pp.1-23.
83 Köppen, U., (2019). Working across disciplines: A manifesto for happy 
newsrooms. Niemen Lab,  [online] 9 July 2019. Available from: https://www.
niemanlab.org/2019/07/working-across-disciplines-a-manifesto-for-happy-
newsrooms/  [19 October 2019]. 
84 Marconi, F., (2020). [Forthcoming]. Newsmakers: Artificial Intelligence and the 
Future of Journalism . Columbia University Press. 
85 Vicari, J., (2019). Venturing into a New World of Journalism. Medium , [online] 
10 January 2019. Available from: https://medium.com/journalism-of-things/
journalism-of-things-65aa481b2dda  [19 October 2019]. 
86 Marconi, F., (2016). Making the internet of things work for journalism. AP Insights, 
[online] 14 July 2016. Available from: https://insights.ap.org/industry-trends/
making-the-internet-of-things-work-for-journalism  [19 October 2019]. 
87 Ward, P ., (2017). Four Ways Augmented Reality Could Save Journalism. 
Medium , [online] 19 November 2017. Available from: https://medium.com/@
peterward85/four-ways-augmented-reality-could-save-journalism-19537272fab0  
[19 October 2019]. 
88 Beckett, C., (2010). The value of networked journalism. POLIS, [online] 11th June 
2010. Available from: http://www.lse.ac.uk/media@lse/POLIS/documents/
Polis%20papers/ValueofNetworkedJournalism.pdf  [19 October 2019]. 
89 Bradshaw, P ., (2007). A model for the 21st century newsroom pt2: Distributed 
Journalism. Online Journalism Blog, [online] 2 October 2007. Available from: 
https://onlinejournalismblog.com/2007/10/02/a-model-for-the-21st-century-
newsroom-pt2-distributed-journalism/  [19 October 2019]. 
105 106
90 Beckett, C., (2019). Emotion as an organising principle for networked journalism. 
LSE Blogs, [online] 17 April 2019. Available from: https://blogs.lse.ac.uk/
polis/2019/04/17/emotion-as-an-organising-principle-for-networked-journalism/  
[19 October 2019]. 
91 The Uber Game., (n.d.) Available from: https://ig.ft.com/uber-game/   
[12 October 2019]. 
92 Kaliouby, R. E., (2019). How do we build trust between humans and AI? World 
Economic Forum , [online] 1 August 2019. Available from: https://www.weforum.
org/agenda/2019/08/can-ai-develop-an-empathetic-bond-with-humanity   
[19 October 2019]. 
Conclusion
93 Newman. J., (2019). How human curation came back to clean up AI’s messes. 
Fast Company, [online] 18 September 2019. Available from: https://www.
fastcompany.com/90402486/how-human-curation-came-back-to-clean-up-ais-
messes  [19 October 2019]. 
94 Juskalian, R., (2008). Interview with Clay Shirky, Part I. Columbia Journalism 
Review, [online] 19 December 2008. Available from: https://archives.cjr.org/
overload/interview_with_clay_shirky_par.php?page=all  [19 October 2019]. 
95 Feldman, M., (2019). There isn’t enough empirical data on the impact of AI. 
HIIG Digital Society Blog, 17 September 2019. Available from: https://www.hiig.
de/en/there-isnt-enough-empirical-data-on-the-impact-of-ai/amp/?__twitter_
impression=true  [19 October 2019]. 
96 Mehra, A., (2019). An Open Letter to Nonmillennials. Medium, [online] 19 
September 2019. Available from: https://onezero.medium.com/an-open-letter-to-
nonmillennials-5d971516e2d7  [19 October 2019]. 
106
Readings and ResourcesReadings and Resources
BOOKS 
Automating the News: how Algorithms are Rewriting the Media
Diakopoulos, N. (June 2019), Harvard University Press
Newsmakers: Artificial Intelligence and the Future of Journalism
Marconi, F. (forthcoming, February 2020), Columbia University Press
REPORTS
The Next Newsroom: Unlocking the Power of AI for Public Service Journalism
European Broadcasting Union, November 2019
News Automation: The rewards, risks and realities of ‘machine journalism’
WAN-IFRA, March 2019
An Industry-Led Debate: How UK media cover artificial intelligence  
Reuters Institute for the Study of Journalism, December 2018
Artificial   Intelligence: Practice   and Implications   for Journalism  
Tow Center for Digital Journalism, Columbia University, September 2017
The Future of Augmented Journalism: A guide for newsrooms in the age of smart machines
Associated Press, April 2017
Guide to Automated Journalism
Tow Center for Digital Journalism, Columbia University, January 2016
MOOCs
Hands-on Machine Learning Solutions for Journalists
JournalismCourses.org, forthcoming, November/December 2019
News Algorithms: The Impact of Automation and AI on Journalism
JournalismCourses.org, February/March 2019
For a wider selection of articles about the applications and implications of AI in journalism, 
with case studies and practical insights, go to blogs.lse.ac.uk/polis . This will be updated 
regularly. Please send us suggestions for further readings and resources.
107 108
AcknowledgmentsThe editorial responsibility for the content of this report lies with the 
author, Professor Charlie Beckett.
Thanks to Anita Zielina, Nic Newman, Ville Kinnunen, and Ana Jakimovska, 
for improving the early drafts of the report with their feedback.
Thanks to lead researcher Fabio Chiusi, and for additional research and 
editing support by Selina Swift.
During two high-level meetings at the start of the survey phase, experts 
working at the intersection of journalism and AI in newsrooms and 
academia generously shared their expertise and recommendations. 
Their contribution was instrumental in allowing this research to start on 
the right track and in the spirit of collaboration.
Along with them, we want to thank Cong Yu and Moustapha Cisse 
of Google AI, whose technical expertise was of great added value in 
designing this research.
Journalism AI  would not have been possible without the support of the 
Google News Initiative. Special thanks to David Dieudonné for his vital 
work to make this happen.
Last but not least, we want to thank again the media organisations  
who made this report possible by taking the Journalism AI survey.  
The complete list follows on the next page:Acknowledgments
108
NEWS ORGANISATIONS THAT COMPLETED THE JOURNALISM AI SURVEY
Agence France-Presse – France
Agora SA – Poland
Aller Media  – Nordics
ARTE – France/Germany
Associated Press  – US
Australia Broadcasting Corporation
Austria Presse Agentur – Austria
Axel Springer SE – Germany
Bayerischer Rundfunk – Germany
BBC – UK
Bloomberg – US
Caerphilly Observer – UK
Central Médiacsoport – Hungary
Chequeado  – Argentina
CNN – US
Condé Nast International
Corriere della Sera  – Italy
Český rozhlas – Czech Republic
Dagens Næringsliv  – Norway
De Standaard / Mediahuis  – Belgium
Der Standard  – Austria
Deutsche Welle – Germany
El Universal  – Mexico
Esquire Singapore  – Singapore
FD Mediagroep – Netherlands
Financial Times  – UK
Folha de S.Paulo  – Brazil
France Télévisions – France
Full Fact – UK
Helsingin Sanomat – Finland
ICIJ
Il Sole 24 Ore – Italy
Inaaj  – India
INK Centre for Investigative Journalism  – 
Botswana
Jysk Fynske Medier – DenmarkKinzen – Ireland
La Stampa – Italy
Le Monde  – France
LETA – Latvia
Los Angeles Times  – US
Malaysiakini  – Malaysia
Mediafin – Belgium
MittMedia  – Sweden
Neue Zürcher Zeitung  – Switzerland
News UK – UK
NPR – US
NRC Media – Netherlands
Observador  – Portugal
openDemocracy  – UK
Poligrafici Editoriale  – Italy
POLITICO
PRISA Noticias – Spain
Quartz – US
Reuters
RTL Deutschland  – Germany
Schibsted Media Group – Nordics
Sky News  – UK
South China Morning Post  – Hong Kong
Spiegel Online  – Germany
Süddeutsche Zeitung  – Germany
Sveriges Television – Sweden
Tamedia AG  – Switzerland
Tempo – Indonesia
Texty – Ukraine
The Economist – UK
The Guardian  – UK
The Washington Post  – US
TRT – Turkey
VPRO  – Netherlands
VRT NWS  – Belgium
Yle – Finland
109
The author welcomes feedback on this report at C.H.Beckett@lse.ac.uk
If you have any questions about the project, or if you want to be 
involved in future Journalism AI initiatives, do not hesitate to get in 
touch with Mattia Peretti at M.Peretti@lse.ac.uk
Get InvolvedGet Involved
Journalism AI, Polis  
Department of Media and Communications  
The London School of Economics  
and Political Science  
Houghton Street  
London WC2A 2AEblogs.lse.ac.uk/polis/2019/11/18/new-powers-new-responsibilities
  @PolisLSE
#JournalismAI